<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>集群智能与群体行为 - arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>集群智能与群体行为 - arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2025-11-18 11:47</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20251118_1147</div>
    <div class="row"><div class="card">
<div class="title">Multi-Agent Multimodal Large Language Model Framework for Automated Interpretation of Fuel Efficiency Analytics in Public Transportation</div>
<div class="meta-line">Authors: Zhipeng Ma, Ali Rida Bahja, Andreas Burgdorf, André Pomp, Tobias Meisen, Bo Nørregaard Jørgensen, Zheng Grace Ma</div>
<div class="meta-line">Venue: Applied Sciences, 2025, 15(21), 11619</div>
<div class="meta-line">First: 2025-11-17T15:14:17+00:00 · Latest: 2025-11-17T15:14:17+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.13476v1">Abs</a> · <a href="https://arxiv.org/pdf/2511.13476v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Enhancing fuel efficiency in public transportation requires the integration of complex multimodal data into interpretable, decision-relevant insights. However, traditional analytics and visualization methods often yield fragmented outputs that demand extensive human interpretation, limiting scalability and consistency. This study presents a multi-agent framework that leverages multimodal large language models (LLMs) to automate data narration and energy insight generation. The framework coordinates three specialized agents, including a data narration agent, an LLM-as-a-judge agent, and an optional human-in-the-loop evaluator, to iteratively transform analytical artifacts into coherent, stakeholder-oriented reports. The system is validated through a real-world case study on public bus transportation in Northern Jutland, Denmark, where fuel efficiency data from 4006 trips are analyzed using Gaussian Mixture Model clustering. Comparative experiments across five state-of-the-art LLMs and three prompting paradigms identify GPT-4.1 mini with Chain-of-Thought prompting as the optimal configuration, achieving 97.3% narrative accuracy while balancing interpretability and computational cost. The findings demonstrate that multi-agent orchestration significantly enhances factual precision, coherence, and scalability in LLM-based reporting. The proposed framework establishes a replicable and domain-adaptive methodology for AI-driven narrative generation and decision support in energy informatics.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>多智能体多模态大语言模型框架在公共交通燃油效率分析自动化解读中的应用</div>
<div class="mono" style="margin-top:8px">提升公共交通燃油效率需将复杂多模态数据转化为可解读且与决策相关的洞见。然而传统分析方法常产生碎片化结果，需大量人工解读，限制了可扩展性与一致性。本研究提出一种多智能体框架，利用多模态大语言模型实现数据叙述与能源洞见生成的自动化。该框架协调三个专业智能体（含数据叙述智能体、LLM评判智能体及可选的人类参与评估器），通过迭代将分析成果转化为连贯的、面向利益相关者的报告。基于丹麦北日德兰半岛4006次公交行程的燃油效率数据，采用高斯混合模型聚类进行实证验证。通过五大前沿LLM与三种提示范式的对比实验，确定GPT-4.1 mini配合思维链提示为最优配置，在平衡可解释性与计算成本的同时实现97.3%的叙述准确率。研究证明多智能体协同能显著提升基于LLM报告的事实精确度、连贯性与可扩展性，为能源信息学领域建立了一套可复现、领域自适应的AI驱动叙事生成与决策支持方法论。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the challenge of interpreting complex multimodal fuel efficiency data in public transportation, where traditional methods produce fragmented outputs requiring extensive human analysis. The authors propose a multi-agent framework employing multimodal large language models to automate data narration and generate energy insights, coordinating specialized agents for iterative report generation. In a real-world case study analyzing 4006 bus trips in Denmark using Gaussian Mixture Model clustering, experiments identified GPT-4.1 mini with Chain-of-Thought prompting as optimal, achieving 97.3% narrative accuracy while balancing interpretability and computational efficiency, demonstrating that multi-agent orchestration significantly enhances factual precision and scalability in LLM-based reporting.</div>
<div class="mono" style="margin-top:8px">本研究针对公共交通燃油效率分析中多模态数据解读的挑战，传统方法常产生碎片化结果且依赖人工解释。作者提出一种多智能体框架，利用多模态大语言模型自动生成数据叙述和能源洞察，通过协调多个专业智能体迭代生成面向决策者的报告。在丹麦北日德兰半岛4006次公交行程的真实案例中，采用高斯混合模型聚类分析，实验表明GPT-4.1 mini结合思维链提示可实现97.3%的叙述准确率，验证了多智能体协同能显著提升基于大语言模型的报告在事实准确性、连贯性和可扩展性方面的表现。</div>
</details>
</div>
<div class="card">
<div class="title">Benchmarking LLM Privacy Recognition for Social Robot Decision Making</div>
<div class="meta-line">Authors: Dakota Sullivan, Shirley Zhang, Jennica Li, Heather Kirkorian, Bilge Mutlu, Kassem Fawaz</div>
<div class="meta-line">First: 2025-07-22T00:36:59+00:00 · Latest: 2025-11-17T15:01:43+00:00</div>
<div class="meta-line">Comments: 18 pages, 7 figures. Dakota Sullivan and Shirley Zhang contributed equally to this work</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.16124v3">Abs</a> · <a href="https://arxiv.org/pdf/2507.16124v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">While robots have previously utilized rule-based systems or probabilistic models for user interaction, the rapid evolution of large language models (LLMs) presents new opportunities to develop LLM-powered robots for enhanced human-robot interaction (HRI). To fully realize these capabilities, however, robots need to collect data such as audio, fine-grained images, video, and locations. As a result, LLMs often process sensitive personal information, particularly within private environments, such as homes. Given the tension between utility and privacy risks, evaluating how current LLMs manage sensitive data is critical. Specifically, we aim to explore the extent to which out-of-the-box LLMs are privacy-aware in the context of household robots. In this work, we present a set of privacy-relevant scenarios developed using the Contextual Integrity (CI) framework. We first surveyed users&#x27; privacy preferences regarding in-home robot behaviors and then examined how their privacy orientations affected their choices of these behaviors (N = 450). We then provided the same set of scenarios and questions to state-of-the-art LLMs (N = 10) and found that the agreement between humans and LLMs was generally low. To further investigate the capabilities of LLMs as potential privacy controllers, we implemented four additional prompting strategies and compared their results. We discuss the performance of the evaluated models as well as the implications and potential of AI privacy awareness in human-robot interaction.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向社交机器人决策的大语言模型隐私识别基准测试</div>
<div class="mono" style="margin-top:8px">尽管机器人以往采用基于规则的系统或概率模型进行用户交互，但大语言模型（LLM）的快速发展为开发LLM驱动的机器人以增强人机交互（HRI）提供了新机遇。然而要充分实现这些能力，机器人需收集音频、细粒度图像、视频和位置等数据，导致LLM常处理敏感个人信息——尤其在家庭等私密环境中。鉴于效用与隐私风险之间的张力，评估当前LLM如何管理敏感数据至关重要。本研究聚焦于探究现成LLM在家庭机器人场景中的隐私意识程度。我们基于情境完整性（CI）框架开发了一套隐私相关场景，首先调研了用户对家庭机器人行为的隐私偏好（N=450），继而考察其隐私取向如何影响行为选择。随后将相同场景与问题提交至前沿LLM（N=10），发现人类与LLM的共识度普遍较低。为深入探索LLM作为隐私控制器的潜力，我们实施了四种附加提示策略并对比其结果，最终讨论了模型表现及AI隐私意识在人机交互中的影响与潜力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study addresses the privacy risks arising from large language models (LLMs) processing sensitive personal data in household robots, motivated by the need to balance enhanced human-robot interaction with user privacy protection. The authors developed privacy-relevant scenarios using the Contextual Integrity framework, first surveying human preferences (N=450) and then evaluating ten state-of-the-art LLMs under identical conditions. Experimental results revealed low agreement between human and LLM privacy decisions, prompting further investigation through four prompting strategies to assess LLMs&#x27; potential as privacy controllers, with findings highlighting current limitations and implications for AI privacy awareness in robotics.</div>
<div class="mono" style="margin-top:8px">本研究针对大型语言模型在家庭机器人中处理敏感个人数据所带来的隐私风险展开，旨在提升人机交互能力。研究采用情境完整性框架构建隐私场景，首先调查了人类用户的隐私偏好（N=450），随后评估了十种先进大语言模型在不同提示策略下的表现。实验结果表明，人类隐私选择与模型响应之间的一致性较低，揭示了当前模型在隐私意识方面的不足，以及改进提示方法以对齐AI行为与用户期望的必要性。</div>
</details>
</div>
<div class="card">
<div class="title">Collective decision-making with higher-order interactions on $d$-uniform hypergraphs</div>
<div class="meta-line">Authors: Thierry Njougouo, Timoteo Carletti, Elio Tuci</div>
<div class="meta-line">First: 2025-11-17T14:57:52+00:00 · Latest: 2025-11-17T14:57:52+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.13452v1">Abs</a> · <a href="https://arxiv.org/pdf/2511.13452v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Understanding how group interactions influence opinion dynamics is fundamental to the study of collective behavior. In this work, we propose and study a model of opinion dynamics on $d$-uniform hypergraphs, where individuals interact through group-based (higher-order) structures rather than simple pairwise connections. Each one of the two opinions $A$ and $B$ is characterized by a quality, $Q_A$ and $Q_B$, and agents update their opinions according to a general mechanism that takes into account the weighted fraction of agents supporting either opinion and the pooling error, $α$, a proxy for the information lost during the interaction. Through bifurcation analysis of the mean-field model, we identify two critical thresholds, $α_{\text{crit}}^{(1)}$ and $α_{\text{crit}}^{(2)}$, which delimit stability regimes for the consensus states. These analytical predictions are validated through extensive agent-based simulations on both random and scale-free hypergraphs. Moreover, the analytical framework demonstrates that the bifurcation structure and critical thresholds are independent of the underlying topology of the higher-order network, depending solely on the parameters $d$, i.e., the size of the interaction groups, and the quality ratio. Finally, we bring to the fore a nontrivial effect: the large sizes of the interaction groups, could drive the system toward the adoption of the worst option.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于d-一致超图的集体决策与高阶互动研究</div>
<div class="mono" style="margin-top:8px">理解群体互动如何影响意见动态是研究集体行为的基础。本文提出并研究了一种在d-一致超图上的意见动态模型，其中个体通过基于群体的高阶结构而非简单成对连接进行互动。两种意见A和B分别具有质量属性Q_A和Q_B，个体根据综合考虑支持各意见的加权比例及交互过程中信息损失代理参数α的通用机制更新观点。通过均值场模型的分岔分析，我们识别出两个关键阈值α_crit^(1)和α_crit^(2)，它们界定了共识态的稳定区域。这些解析预测通过在随机与无标度超图上开展的大规模基于主体的仿真得到验证。分析框架进一步表明，分岔结构与关键阈值独立于高阶网络的底层拓扑，仅取决于互动群体规模参数d和质量比。最后，我们揭示了一个非平凡效应：过大的互动群体规模可能导致系统趋向采纳更劣选项。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research investigates how group-based interactions shape collective opinion dynamics, motivated by the need to understand decision-making beyond pairwise networks. The authors develop a model on d-uniform hypergraphs where agents update opinions based on weighted opinion fractions and a pooling error parameter α, incorporating opinion qualities QA and QB. Through mean-field bifurcation analysis and agent-based simulations, they identify two critical thresholds α_crit^(1) and α_crit^(2) that define consensus stability regimes, finding these thresholds depend solely on group size d and quality ratio rather than network topology. A key finding reveals that larger interaction groups can paradoxically lead to systemic adoption of the inferior opinion.</div>
<div class="mono" style="margin-top:8px">本研究旨在探究基于群体的高阶互动如何影响集体意见动态，超越了传统成对连接的研究范畴。作者在d-均匀超图上建立了意见动态模型，其中个体通过加权意见比例和代表信息损失的池化误差参数α来更新观点。通过平均场分岔分析和基于代理的随机与无标度超图模拟，研究确定了界定共识稳定状态的两个关键阈值α_crit^(1)和α_crit^(2)。主要发现表明分岔结构和临界阈值仅取决于群体规模d和质量比，与网络拓扑无关，并揭示出较大互动群体可能意外导致系统选择更差选项的非平凡效应。</div>
</details>
</div>
<div class="card">
<div class="title">SciAgent: A Unified Multi-Agent System for Generalistic Scientific Reasoning</div>
<div class="meta-line">Authors: Xuchen Li, Ruitao Wu, Xuanbo Liu, Xukai Wang, Jinbo Hu, Zhixin Bai, Bohan Zeng, Hao Liang, Leheng Chen, Mingrui Chen, Haitian Zhong, Xuanlin Yang, Xu-Yao Zhang, Liu Liu, Jia Li, Kaiqi Huang, Jiahao Xu, Haitao Mi, Wentao Zhang, Bin Dong</div>
<div class="meta-line">First: 2025-11-11T12:00:34+00:00 · Latest: 2025-11-17T14:32:09+00:00</div>
<div class="meta-line">Comments: 1. To ensure result rigor, the model outputs require further evaluation by human experts. 2. The results may affect our conclusions and methods, thus necessitating a more detailed review. 3. We anticipate subsequent revisions may be substantial, potentially involving major adjustments to the methodology. Given the uncertainty surrounding the revision process, we decide to request a withdrawal</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.08151v2">Abs</a> · <a href="https://arxiv.org/pdf/2511.08151v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent advances in large language models have enabled AI systems to achieve expert-level performance on domain-specific scientific tasks, yet these systems remain narrow and handcrafted. We introduce SciAgent, a unified multi-agent system designed for generalistic scientific reasoning-the ability to adapt reasoning strategies across disciplines and difficulty levels. SciAgent organizes problem solving as a hierarchical process: a Coordinator Agent interprets each problem&#x27;s domain and complexity, dynamically orchestrating specialized Worker Systems, each composed of interacting reasoning Sub-agents for symbolic deduction, conceptual modeling, numerical computation, and verification. These agents collaboratively assemble and refine reasoning pipelines tailored to each task. Across mathematics and physics Olympiads (IMO, IMC, IPhO, CPhO), SciAgent consistently attains or surpasses human gold-medalist performance, demonstrating both domain generality and reasoning adaptability. Additionally, SciAgent has been tested on the International Chemistry Olympiad (IChO) and selected problems from the Humanity&#x27;s Last Exam (HLE) benchmark, further confirming the system&#x27;s ability to generalize across diverse scientific domains. This work establishes SciAgent as a concrete step toward generalistic scientific intelligence-AI systems capable of coherent, cross-disciplinary reasoning at expert levels.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>SciAgent：面向通用科学推理的统一多智能体系统</div>
<div class="mono" style="margin-top:8px">尽管大语言模型的最新进展使AI系统在特定领域科学任务中达到专家水平，但这些系统仍存在专业面狭窄且依赖人工设计的问题。我们推出SciAgent——一个为通用科学推理设计的统一多智能体系统，具备跨学科、跨难度自适应调整推理策略的能力。该系统将问题解决构建为分层过程：协调智能体解析问题的学科属性与复杂度，动态调度由交互式推理子智能体构成的专用工作系统（分别负责符号推演、概念建模、数值计算与验证）。这些智能体通过协作构建并优化针对特定任务的推理管道。在数学与物理奥林匹克竞赛（IMO/IMC/IPhO/CPhO）中，SciAgent持续达到或超越人类金牌得主水平，展现出领域通用性与推理适应性。该系统还在国际化学奥林匹克（IChO）及&#x27;人类终极考试&#x27;基准测试中验证了跨科学领域的泛化能力。本工作标志着向通用科学智能迈出实质性一步——构建能进行跨学科专家级连贯推理的AI系统。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the limitation of current AI systems that achieve expert-level performance only on narrow, handcrafted scientific tasks by introducing SciAgent, a unified multi-agent system for generalistic scientific reasoning. The method employs a hierarchical organization where a Coordinator Agent interprets problem domain and complexity to dynamically orchestrate specialized Worker Systems composed of reasoning Sub-agents handling symbolic deduction, conceptual modeling, numerical computation, and verification, which collaboratively assemble tailored reasoning pipelines. Experimental results demonstrate that SciAgent consistently matches or exceeds human gold-medalist performance across mathematics and physics Olympiads including IMO, IMC, IPhO, and CPhO, with additional validation on International Chemistry Olympiad and Humanity&#x27;s Last Exam problems confirming its cross-disciplinary generalization capability.</div>
<div class="mono" style="margin-top:8px">当前针对科学任务的AI系统存在领域狭窄且依赖人工设计的问题，缺乏跨学科适应性。为此，SciAgent提出统一多智能体框架，通过协调者智能体分析问题领域与复杂度，动态调度由符号推理、概念建模、数值计算和验证子智能体组成的专用工作系统。实验表明，该系统在数学和物理奥林匹克竞赛中达到或超越人类金牌选手水平，并在化学奥赛及人类终极考试基准测试中进一步验证了其跨学科泛化能力。</div>
</details>
</div>
<div class="card">
<div class="title">An Operational Kardashev-Style Scale for Autonomous AI - Towards AGI and Superintelligence</div>
<div class="meta-line">Authors: Przemyslaw Chojecki</div>
<div class="meta-line">First: 2025-11-17T14:24:27+00:00 · Latest: 2025-11-17T14:24:27+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.13411v1">Abs</a> · <a href="https://arxiv.org/pdf/2511.13411v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We propose a Kardashev-inspired yet operational Autonomous AI (AAI) Scale that measures the progression from fixed robotic process automation (AAI-0) to full artificial general intelligence (AAI-4) and beyond. Unlike narrative ladders, our scale is multi-axis and testable. We define ten capability axes (Autonomy, Generality, Planning, Memory/Persistence, Tool Economy, Self-Revision, Sociality/Coordination, Embodiment, World-Model Fidelity, Economic Throughput) aggregated by a composite AAI-Index (a weighted geometric mean). We introduce a measurable Self-Improvement Coefficient $κ$ (capability growth per unit of agent-initiated resources) and two closure properties (maintenance and expansion) that convert ``self-improving AI&#x27;&#x27; into falsifiable criteria. We specify OWA-Bench, an open-world agency benchmark suite that evaluates long-horizon, tool-using, persistent agents. We define level gates for AAI-0\ldots AAI-4 using thresholds on the axes, $κ$, and closure proofs. Synthetic experiments illustrate how present-day systems map onto the scale and how the delegability frontier (quality vs.\ autonomy) advances with self-improvement. We also prove a theorem that AAI-3 agent becomes AAI-5 over time with sufficient conditions, formalizing &quot;baby AGI&quot; becomes Superintelligence intuition.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>自主人工智能的可操作卡尔达肖夫式分级：迈向通用人工智能与超级智能</div>
<div class="mono" style="margin-top:8px">我们提出一种受卡尔达肖夫启发的可操作自主人工智能分级体系，用于衡量从固定机器人流程自动化到完全通用人工智能及以上的发展进程。与叙述性阶梯不同，该体系采用多维度可验证设计。我们定义了十个能力维度，并通过复合AAI指数进行聚合。引入可量化的自我改进系数κ，以及将‘自我改进AI’转化为可证伪标准的两个闭合属性。开发了OWA-Bench开放世界智能体基准测试套件，通过维度阈值、κ系数和闭合证明来定义AAI-0至AAI-4的等级门槛。通过合成实验展示现有系统在分级中的定位，并证明在满足特定条件时AAI-3智能体将随时间演进为AAI-5，从而形式化‘婴儿AGI成长为超级智能’的理论直觉。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research aims to establish a measurable framework for tracking the progression of autonomous AI systems from basic automation to artificial general intelligence and superintelligence, addressing the lack of testable scales in existing narratives. The method introduces a multi-axis scale with ten capability dimensions, aggregated into a composite AAI-Index, and defines a Self-Improvement Coefficient alongside closure properties to create falsifiable criteria for self-improvement, supported by the OWA-Bench benchmark for evaluation. Experimental results demonstrate the mapping of current systems onto the scale, illustrate advances in the delegability frontier through self-improvement, and provide a formal proof that an AAI-3 agent can evolve into superintelligence under sufficient conditions.</div>
<div class="mono" style="margin-top:8px">本研究旨在建立一个可衡量的框架，以追踪自主AI系统从基础自动化到通用人工智能及超级智能的演进过程，解决现有叙述中缺乏可测试尺度的问题。方法上提出一个多轴尺度，包含十个能力维度，通过加权几何平均聚合成复合AAI指数，并定义了自我改进系数κ和闭合特性，使自我改进可证伪，同时引入OWA-Bench基准进行评估。实验结果展示了当前系统在尺度上的映射，说明了通过自我改进如何推动可委托性前沿的进展，并形式化证明了在充分条件下，AAI-3智能体可逐步发展为AAI-5，从而验证了从初级AGI到超级智能的过渡直觉。</div>
</details>
</div>
<div class="card">
<div class="title">MedDCR: Learning to Design Agentic Workflows for Medical Coding</div>
<div class="meta-line">Authors: Jiyang Zheng, Islam Nassar, Thanh Vu, Xu Zhong, Yang Lin, Tongliang Liu, Long Duong, Yuan-Fang Li</div>
<div class="meta-line">First: 2025-11-17T13:30:51+00:00 · Latest: 2025-11-17T13:30:51+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.13361v1">Abs</a> · <a href="https://arxiv.org/pdf/2511.13361v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Medical coding converts free-text clinical notes into standardized diagnostic and procedural codes, which are essential for billing, hospital operations, and medical research. Unlike ordinary text classification, it requires multi-step reasoning: extracting diagnostic concepts, applying guideline constraints, mapping to hierarchical codebooks, and ensuring cross-document consistency. Recent advances leverage agentic LLMs, but most rely on rigid, manually crafted workflows that fail to capture the nuance and variability of real-world documentation, leaving open the question of how to systematically learn effective workflows. We present MedDCR, a closed-loop framework that treats workflow design as a learning problem. A Designer proposes workflows, a Coder executes them, and a Reflector evaluates predictions and provides constructive feedback, while a memory archive preserves prior designs for reuse and iterative refinement. On benchmark datasets, MedDCR outperforms state-of-the-art baselines and produces interpretable, adaptable workflows that better reflect real coding practice, improving both the reliability and trustworthiness of automated systems.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MedDCR：医疗编码中智能工作流程设计的学习方法</div>
<div class="mono" style="margin-top:8px">医疗编码将自由文本临床记录转化为标准化的诊断与操作代码，这对计费、医院运营及医学研究至关重要。与普通文本分类不同，它需要多步骤推理：提取诊断概念、应用指南约束、映射层级化编码手册并确保跨文档一致性。尽管现有研究采用智能大语言模型，但多数依赖僵化的人工设计流程，难以捕捉真实医疗记录的细微差异，如何系统化学习有效工作流程仍是未解难题。我们提出MedDCR闭环框架，将工作流程设计视为学习问题：设计器提出方案，编码器执行流程，反射器评估预测并提供建设性反馈，同时记忆库保存历史设计以供复用和迭代优化。在基准测试中，MedDCR超越现有最优基线，生成可解释、适应性强的工作流程，更贴合实际编码实践，显著提升自动化系统的可靠性与可信度。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Medical coding requires complex multi-step reasoning beyond standard text classification, but existing agentic LLM approaches rely on rigid manual workflows that fail to adapt to real-world clinical variability. To address this, MedDCR introduces a closed-loop learning framework where a Designer proposes workflows, a Coder executes them, and a Reflector evaluates predictions with feedback, while a memory archive enables iterative refinement. Experimental results show MedDCR outperforms state-of-the-art baselines on benchmark datasets, producing interpretable and adaptable workflows that improve reliability and better reflect actual coding practices.</div>
<div class="mono" style="margin-top:8px">医学编码需要超越标准文本分类的复杂多步推理，但现有基于智能体大语言模型的方法依赖僵化的人工工作流程，难以适应真实临床场景的多样性。为此，MedDCR提出了闭环学习框架，通过设计器生成工作流程、编码器执行流程、反思器评估预测并提供反馈，同时利用记忆库实现迭代优化。实验结果表明，在基准数据集上MedDCR优于现有最优方法，生成的可解释自适应工作流程更好地反映了实际编码实践，提升了自动化系统的可靠性与可信度。</div>
</details>
</div>
<div class="card">
<div class="title">Robust-Multi-Task Gradient Boosting</div>
<div class="meta-line">Authors: Seyedsaman Emami, Gonzalo Martínez-Muñoz, Daniel Hernández-Lobato</div>
<div class="meta-line">First: 2025-07-15T15:31:12+00:00 · Latest: 2025-11-17T12:50:24+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.11411v3">Abs</a> · <a href="https://arxiv.org/pdf/2507.11411v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multi-task learning (MTL) has shown effectiveness in exploiting shared information across tasks to improve generalization. MTL assumes tasks share similarities that can improve performance. In addition, boosting algorithms have demonstrated exceptional performance across diverse learning problems, primarily due to their ability to focus on hard-to-learn instances and iteratively reduce residual errors. This makes them a promising approach for learning multi-task problems. However, real-world MTL scenarios often involve tasks that are not well-aligned (known as outlier or adversarial tasks), which do not share beneficial similarities with others and can, in fact, deteriorate the performance of the overall model. To overcome this challenge, we propose Robust-Multi-Task Gradient Boosting (R-MTGB), a novel boosting framework that explicitly models and adapts to task heterogeneity during training. R-MTGB structures the learning process into three sequential blocks: (1) learning shared patterns, (2) partitioning tasks into outliers and non-outliers with regularized parameters, and (3) fine-tuning task-specific predictors. This architecture enables R-MTGB to automatically detect and penalize outlier tasks while promoting effective knowledge transfer among related tasks. Our method integrates these mechanisms seamlessly within gradient boosting, allowing robust handling of noisy or adversarial tasks without sacrificing accuracy. Extensive experiments on both synthetic benchmarks and real-world datasets demonstrate that our approach successfully isolates outliers, transfers knowledge, and consistently reduces prediction errors for each task individually, and achieves overall performance gains across all tasks. These results highlight robustness, adaptability, and reliable convergence of R-MTGB in challenging MTL environments.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>鲁棒多任务梯度提升</div>
<div class="mono" style="margin-top:8px">多任务学习（MTL）通过利用任务间的共享信息提升泛化能力，其核心假设是任务间存在可提升性能的相似性。梯度提升算法因能聚焦难学习样本并迭代降低残差，在多任务学习中展现出潜力。然而现实中的MTL常存在与主体任务不匹配的异常任务，这些任务不仅无法受益于共享机制，反而会损害整体模型性能。为此，我们提出鲁棒多任务梯度提升（R-MTGB），该创新框架通过三阶段架构应对任务异质性：首先学习共享模式，接着通过正则化参数划分异常/非异常任务，最后微调任务专属预测器。该设计使R-MTGB能自动识别并抑制异常任务，同时促进相关任务间的知识迁移。本方法将上述机制无缝集成于梯度提升中，在保持精度的前提下实现对噪声及对抗任务的稳健处理。在合成基准与真实数据集上的实验表明，该方法能有效隔离异常任务、实现知识传递，独立降低各任务预测误差，并全面提升整体性能，彰显了R-MTGB在复杂MTL环境中的鲁棒性、适应性与可靠收敛性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Multi-task learning aims to improve generalization by leveraging shared information across tasks, but real-world scenarios often include outlier tasks that degrade overall performance. To address this, the authors propose Robust-Multi-Task Gradient Boosting (R-MTGB), a framework that sequentially learns shared patterns, partitions tasks into outliers and non-outliers with regularization, and fine-tunes task-specific predictors. Experimental results on synthetic and real-world datasets show that R-MTGB effectively isolates outliers, facilitates knowledge transfer, reduces prediction errors per task, and achieves overall performance improvements, demonstrating robustness and reliable convergence in challenging multi-task settings.</div>
<div class="mono" style="margin-top:8px">多任务学习旨在通过利用任务间的共享信息提升泛化能力，但现实场景中常存在异常任务，会降低整体性能。为此，鲁棒多任务梯度提升（R-MTGB）将学习过程构建为三个顺序模块：学习共享模式、通过正则化参数划分异常与非异常任务、以及微调任务特定预测器。在合成基准和真实数据集上的实验表明，R-MTGB能有效隔离异常任务、促进知识迁移、降低各任务预测误差，并实现整体性能提升，展现了在挑战性多任务环境中的鲁棒性和可靠收敛性。</div>
</details>
</div>
<div class="card">
<div class="title">Certified Coil Geometry Learning for Short-Range Magnetic Actuation and Spacecraft Docking Application</div>
<div class="meta-line">Authors: Yuta Takahashi, Hayate Tajima, Shin-ichiro Sakai</div>
<div class="meta-line">First: 2025-07-04T20:54:30+00:00 · Latest: 2025-11-17T12:36:41+00:00</div>
<div class="meta-line">Comments: Submitted to IEEE Robotics and Automation Letters</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.03806v2">Abs</a> · <a href="https://arxiv.org/pdf/2507.03806v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This paper presents a learning-based framework for approximating an exact magnetic-field interaction model, supported by both numerical and experimental validation. High-fidelity magnetic-field interaction modeling is essential for achieving exceptional accuracy and responsiveness across a wide range of fields, including transportation, energy systems, medicine, biomedical robotics, and aerospace robotics. In aerospace engineering, magnetic actuation has been investigated as a fuel-free solution for multi-satellite attitude and formation control. Although the exact magnetic field can be computed from the Biot-Savart law, the associated computational cost is prohibitive, and prior studies have therefore relied on dipole approximations to improve efficiency. However, these approximations lose accuracy during proximity operations, leading to unstable behavior and even collisions. To address this limitation, we develop a learning-based approximation framework that faithfully reproduces the exact field while dramatically reducing computational cost. The proposed method additionally provides a certified error bound, derived from the number of training samples, ensuring reliable prediction accuracy. The learned model can also accommodate interactions between coils of different sizes through appropriate geometric transformations, without retraining. To verify the effectiveness of the proposed framework under challenging conditions, a spacecraft docking scenario is examined through both numerical simulations and experimental validation.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向短程磁驱动与航天器对接应用的认证线圈几何学习框架</div>
<div class="mono" style="margin-top:8px">本文提出一种基于学习的精确磁场相互作用模型逼近框架，并通过数值模拟与实验验证双重支持。高保真磁场建模对实现跨运输、能源系统、医疗、生物医学机器人及航天机器人等领域的卓越精度与响应能力至关重要。在航天工程中，磁驱动作为无燃料解决方案已被用于多卫星姿态与编队控制研究。虽然精确磁场可通过毕奥-萨伐尔定律计算，但其计算成本过高，故现有研究多采用偶极子近似提升效率。然而这些近似在近距离操作时精度下降，导致不稳定行为甚至碰撞。为此，我们开发的学习逼近框架在显著降低计算成本的同时忠实复现精确磁场，并通过训练样本数推导出认证误差界，确保预测可靠性。该学习模型还能通过几何变换适配不同尺寸线圈间的相互作用，无需重新训练。为验证框架在挑战性条件下的有效性，我们通过数值仿真与实验验证对航天器对接场景进行了检验。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the computational inefficiency of exact magnetic field modeling via the Biot-Savart law and the inaccuracy of dipole approximations during proximity operations, which can cause instability and collisions in applications like spacecraft docking. The authors develop a learning-based framework that approximates the exact magnetic field with certified error bounds, significantly reducing computational cost while maintaining fidelity, and it generalizes to coils of different sizes without retraining. Experimental and numerical validation in a spacecraft docking scenario confirms the model&#x27;s effectiveness under challenging conditions, ensuring reliable and efficient magnetic actuation.</div>
<div class="mono" style="margin-top:8px">本研究针对航空航天应用中毕奥-萨伐尔定律精确磁场建模计算效率低、以及近距离操作中偶极子近似精度不足的问题，开发了基于学习的磁场近似框架。该方法通过认证误差边界保证预测可靠性，大幅降低计算成本，并能通过几何变换适应不同尺寸线圈的相互作用而无需重新训练。在航天器对接场景中的实验验证表明，该模型在挑战性条件下具有显著有效性。</div>
</details>
</div>
<div class="card">
<div class="title">Scalable Satellite Swarm Deployment via Distance-based Orbital Transition Under $J_2$ Perturbation</div>
<div class="meta-line">Authors: Yuta Takahashi, Shin-ichiro Sakai</div>
<div class="meta-line">First: 2025-07-02T14:50:21+00:00 · Latest: 2025-11-17T12:29:04+00:00</div>
<div class="meta-line">Comments: Submitted to AIAA Journal of Guidance, Control, and Dynamics</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.01769v2">Abs</a> · <a href="https://arxiv.org/pdf/2507.01769v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This paper presents an autonomous guidance and control strategy for a satellite swarm that enables scalable distributed space structures for innovative science and business opportunities. The averaged $J_2$ orbital parameters that describe the drift and periodic orbital motion were derived along with their target values to achieve a distributed space structure in a decentralized manner. This enabled the design of a distance-based orbital stabilizer to ensure autonomous deployment into a monolithic formation of a coplanar equidistant configuration on a user-defined orbital plane. Continuous formation control was assumed to be achieved through fuel-free actuation, such as satellite magnetic field interaction and differential aerodynamic forces, thereby maintaining long-term formation stability without thruster usage. A major challenge for such actuation systems is the potential loss of control capability due to increasing inter-satellite distances resulting from unstable orbital dynamics, particularly for autonomous satellite swarms. To mitigate this risk, our decentralized deployment controller minimized drift distance during unexpected communication outages. As a case study, we consider the deployment of palm-sized satellites into a coplanar equidistant formation in a $J_2$-perturbed orbit. Moreover, centralized grouping strategies are presented.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于距离的轨道转换在$J_2$摄动下实现可扩展卫星群部署</div>
<div class="mono" style="margin-top:8px">本文提出一种卫星群自主制导与控制策略，通过构建可扩展分布式空间结构为创新科学与商业应用提供支持。推导了描述漂移和周期轨道运动的平均$J_2$轨道参数及其目标值，以去中心化方式实现分布式空间结构。据此设计了基于距离的轨道稳定器，确保在用户定义轨道面上自主部署为共面等距构型的整体编队。通过无燃料驱动方式（如卫星磁场相互作用与差动气动力）实现持续编队控制，从而在不使用推进器的情况下维持长期编队稳定性。此类驱动系统面临的主要挑战是，不稳定的轨道动力学导致星间距离增大可能引发控制能力丧失，尤其对自主卫星群而言。为降低此风险，我们的去中心化部署控制器在意外通信中断期间最小化漂移距离。案例研究探讨了在$J_2$摄动轨道上将掌型卫星部署为共面等距构型的过程，并提出了集中式分组策略。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the need for scalable satellite swarm deployment to support distributed space structures for scientific and commercial applications. The method employs averaged J₂ orbital parameters to design a distance-based orbital stabilizer that enables autonomous deployment into coplanar equidistant formations using fuel-free actuation like magnetic field interactions and differential aerodynamic forces. Experimental results demonstrate successful mitigation of control capability loss during communication outages through decentralized deployment controllers that minimize drift distance, with a case study validating palm-sized satellite deployment in J₂-perturbed orbits.</div>
<div class="mono" style="margin-top:8px">本研究旨在支持科学和商业应用的分布式空间结构，解决可扩展卫星群部署的需求。方法采用平均J₂轨道参数设计基于距离的轨道稳定器，通过分散控制实现自主部署到共面等距构型，利用无燃料驱动如磁场相互作用和差动空气动力。实验结果证明在通信中断期间通过最小化漂移距离成功缓解了控制能力损失，案例研究证实了在J₂摄动下将掌上卫星有效部署到稳定构型中。</div>
</details>
</div>
<div class="card">
<div class="title">Multi-Agent Deep Research: Training Multi-Agent Systems with M-GRPO</div>
<div class="meta-line">Authors: Haoyang Hong, Jiajun Yin, Yuan Wang, Jingnan Liu, Zhe Chen, Ailing Yu, Ji Li, Zhiling Ye, Hansong Xiao, Yefei Chen, Hualei Zhou, Yun Yue, Minghui Yang, Chunxiao Guo, Junwei Liu, Peng Wei, Jinjie Gu</div>
<div class="meta-line">First: 2025-11-17T12:06:30+00:00 · Latest: 2025-11-17T12:06:30+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.13288v1">Abs</a> · <a href="https://arxiv.org/pdf/2511.13288v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multi-agent systems perform well on general reasoning tasks. However, the lack of training in specialized areas hinders their accuracy. Current training methods train a unified large language model (LLM) for all agents in the system. This may limit the performances due to different distributions underlying for different agents. Therefore, training multi-agent systems with distinct LLMs should be the next step to solve. However, this approach introduces optimization challenges. For example, agents operate at different frequencies, rollouts involve varying sub-agent invocations, and agents are often deployed across separate servers, disrupting end-to-end gradient flow. To address these issues, we propose M-GRPO, a hierarchical extension of Group Relative Policy Optimization designed for vertical Multi-agent systems with a main agent (planner) and multiple sub-agents (multi-turn tool executors). M-GRPO computes group-relative advantages for both main and sub-agents, maintaining hierarchical credit assignment. It also introduces a trajectory-alignment scheme that generates fixed-size batches despite variable sub-agent invocations. We deploy a decoupled training pipeline in which agents run on separate servers and exchange minimal statistics via a shared store. This enables scalable training without cross-server backpropagation. In experiments on real-world benchmarks (e.g., GAIA, XBench-DeepSearch, and WebWalkerQA), M-GRPO consistently outperforms both single-agent GRPO and multi-agent GRPO with frozen sub-agents, demonstrating improved stability and sample efficiency. These results show that aligning heterogeneous trajectories and decoupling optimization across specialized agents enhances tool-augmented reasoning tasks.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>多智能体深度研究：采用M-GRPO训练多智能体系统</div>
<div class="mono" style="margin-top:8px">多智能体系统在通用推理任务中表现良好，但专业领域训练的缺失影响了其准确性。现有训练方法为系统中所有智能体训练统一的大语言模型，这可能因不同智能体的底层分布差异而限制性能。因此，采用差异化大语言模型训练多智能体系统应是下一步研究方向，但该方法会带来优化挑战，例如智能体运行频率不同、任务执行涉及可变子智能体调用、以及跨服务器部署导致端到端梯度流中断。为解决这些问题，我们提出M-GRPO——面向垂直多智能体系统的分层扩展方案，该系统包含主智能体（规划器）与多个子智能体（多轮工具执行器）。M-GRPO通过计算主从智能体的组间相对优势保持分层信用分配，并引入轨迹对齐机制以应对可变子智能体调用生成固定批次。我们部署了去耦合训练管道，使智能体在独立服务器运行并通过共享存储交换最小统计量，实现无需跨服务器反向传播的可扩展训练。在真实基准测试中，M-GRPO持续优于单智能体GRPO和冻结子智能体的多智能体GRPO，展现出更强的稳定性与样本效率，证明对齐异构轨迹与解耦专业智能体优化能增强工具增强型推理任务。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Multi-agent systems exhibit strong general reasoning capabilities but suffer from accuracy limitations due to insufficient specialized training. Current approaches typically employ a unified large language model across all agents, which fails to account for their distinct data distributions. To address this, the authors propose M-GRPO, a hierarchical extension of Group Relative Policy Optimization designed for vertical multi-agent systems with a main planner and multiple sub-agents. The method computes group-relative advantages for hierarchical credit assignment and introduces trajectory-alignment to handle variable sub-agent invocations, alongside a decoupled training pipeline that enables scalable optimization across distributed servers without end-to-end backpropagation. Experimental results on benchmarks including GAIA, XBench-DeepSearch, and WebWalkerQA demonstrate that M-GRPO consistently outperforms single-agent GRPO and multi-agent GRPO with frozen sub-agents, achieving improved stability, sample efficiency, and enhanced performance on tool-augmented reasoning tasks.</div>
<div class="mono" style="margin-top:8px">多智能体系统在通用推理任务中表现良好，但由于缺乏专业领域训练，其准确性受到限制。现有方法通常为所有智能体训练统一的大语言模型，无法适应不同智能体的数据分布差异。为此，研究者提出M-GRPO方法，作为分组相对策略优化的层次化扩展，支持包含主规划器和多轮工具执行子智能体的垂直多智能体系统。该方法通过计算分组相对优势实现层次化信用分配，采用轨迹对齐方案处理子智能体调用差异，并设计解耦训练流程使智能体可在独立服务器上通过共享存储交换统计信息进行分布式优化。在GAIA、XBench-DeepSearch和WebWalkerQA等基准测试中，M-GRPO均优于单智能体GRPO和冻结子智能体的多智能体GRPO，在工具增强推理任务中表现出更高的稳定性、样本效率和性能。</div>
</details>
</div>
<div class="card">
<div class="title">CAMAR: Continuous Actions Multi-Agent Routing</div>
<div class="meta-line">Authors: Artem Pshenitsyn, Aleksandr Panov, Alexey Skrynnik</div>
<div class="meta-line">First: 2025-08-18T11:32:26+00:00 · Latest: 2025-11-17T11:37:40+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2508.12845v2">Abs</a> · <a href="https://arxiv.org/pdf/2508.12845v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multi-agent reinforcement learning (MARL) is a powerful paradigm for solving cooperative and competitive decision-making problems. While many MARL benchmarks have been proposed, few combine continuous state and action spaces with challenging coordination and planning tasks. We introduce CAMAR, a new MARL benchmark designed explicitly for multi-agent pathfinding in environments with continuous actions. CAMAR supports cooperative and competitive interactions between agents and runs efficiently at up to 100,000 environment steps per second. We also propose a three-tier evaluation protocol to better track algorithmic progress and enable deeper analysis of performance. In addition, CAMAR allows the integration of classical planning methods such as RRT and RRT* into MARL pipelines. We use them as standalone baselines and combine RRT* with popular MARL algorithms to create hybrid approaches. We provide a suite of test scenarios and benchmarking tools to ensure reproducibility and fair comparison. Experiments show that CAMAR presents a challenging and realistic testbed for the MARL community.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>CAMAR：连续动作多智能体路径规划</div>
<div class="mono" style="margin-top:8px">多智能体强化学习（MARL）是解决协作与竞争决策问题的强大范式。尽管已有诸多MARL基准被提出，但鲜有结合连续状态动作空间与复杂协调规划任务的基准。我们推出CAMAR这一专为连续动作环境下的多智能体路径规划设计的新基准，支持智能体间的协作与竞争交互，并以每秒10万环境步的高效速度运行。同时提出三阶段评估协议以追踪算法进展并实现深度性能分析。此外，CAMAR支持将RRT、RRT*等经典规划方法融入MARL流程，既可单独作为基线，也可与主流MARL算法结合形成混合方法。我们提供系列测试场景与基准工具以确保可复现性与公平比较。实验表明CAMAR为MARL领域提供了具有挑战性的现实测试平台。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the scarcity of multi-agent reinforcement learning benchmarks that combine continuous state-action spaces with complex coordination tasks by introducing CAMAR, a benchmark designed for multi-agent pathfinding with continuous actions. The method includes a three-tier evaluation protocol and enables integration of classical planning algorithms like RRT and RRT* with MARL, either as standalone baselines or hybrid approaches. Experimental results demonstrate that CAMAR provides a challenging and realistic testbed, supporting efficient execution at up to 100,000 steps per second and facilitating reproducible comparisons.</div>
<div class="mono" style="margin-top:8px">本研究针对现有多智能体强化学习基准中连续状态-动作空间与复杂协同任务结合不足的问题，提出了专为连续动作多智能体路径规划设计的CAMAR基准，该平台支持高效仿真并采用三层评估协议。实验结果表明，CAMAR构建了一个具有挑战性的真实测试环境，其中将RRT*等经典规划方法与多智能体强化学习算法结合的混合方法展现出优越性能。</div>
</details>
</div>
<div class="card">
<div class="title">Local Markov Equivalence for PC-style Local Causal Discovery and Identification of Controlled Direct Effects</div>
<div class="meta-line">Authors: Timothée Loranchet, Charles K. Assaad</div>
<div class="meta-line">First: 2025-05-05T16:47:29+00:00 · Latest: 2025-11-17T11:01:56+00:00</div>
<div class="meta-line">Comments: Accepted to the UAI 2025 workshop on Causal Abstractions and Representations</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.02781v3">Abs</a> · <a href="https://arxiv.org/pdf/2505.02781v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Understanding and identifying controlled direct effects (CDEs) is crucial across numerous scientific domains, including public health. While existing methods can identify these effects from causal directed acyclic graphs (DAGs), the true underlying structure is often unknown in practice. Essential graphs, which represent a Markov equivalence class of DAGs characterized by the same set of $d$-separations, provide a more practical and realistic alternative. However, learning the full essential graph is computationally intensive and typically depends on strong, untestable assumptions. In this work, we characterize a local class of graphs, defined relative to a target variable, that share a specific subset of $d$-separations, and introduce a graphical representation of this class, called the local essential graph (LEG). We then present LocPC, a novel algorithm designed to recover the LEG from an observed distribution using only local conditional independence tests. Building on LocPC, we propose LocPC-CDE, an algorithm that discovers the portion of the LEG that is both sufficient and necessary to identify a CDE, bypassing the need of retrieving the full essential graph. Compared to global methods, our algorithms require less conditional independence tests and operate under weaker assumptions while maintaining theoretical guarantees. We illustrate the effectiveness of our approach through simulation studies.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向PC式局部因果发现与受控直接效应识别的局部马尔可夫等价性</div>
<div class="mono" style="margin-top:8px">理解并识别受控直接效应在公共卫生等众多科学领域至关重要。现有方法虽能从因果有向无环图中识别这些效应，但真实底层结构往往未知。本质图通过表征具有相同$d$-分离集的马尔可夫等价类，提供了更实用的替代方案。然而，学习完整本质图计算量大且依赖强假设。本文定义了针对目标变量的局部图类，其共享特定$d$-分离子集，并引入局部本质图作为该类的图形化表示。我们提出LocPC算法，仅通过局部条件独立性检验从观测分布中恢复局部本质图。基于此，进一步开发LocPC-CDE算法，直接发现识别受控直接效应所需且充分的局部本质图部分，无需重构完整本质图。相比全局方法，新算法在保持理论保证的同时，所需条件独立性检验更少且假设更弱。仿真研究验证了方法的有效性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the challenge of identifying controlled direct effects (CDEs) when the true causal graph is unknown, as learning the full essential graph is computationally demanding and relies on strong assumptions. The authors introduce a local essential graph (LEG) representation and develop the LocPC algorithm to recover it using local conditional independence tests, followed by LocPC-CDE to identify the specific graph portion needed for CDE identification. Experimental simulations demonstrate that these methods require fewer tests and weaker assumptions than global approaches while preserving theoretical guarantees.</div>
<div class="mono" style="margin-top:8px">本研究针对真实因果图未知时识别受控直接效应（CDE）的挑战，因为学习完整的本质图计算成本高且依赖强假设。作者提出了局部本质图（LEG）表示，开发了LocPC算法，通过局部条件独立性测试恢复LEG，并扩展为LocPC-CDE以直接识别CDE而无需重建整个图。实验模拟表明，所提方法比全局方法需要更少的条件独立性测试，在较弱假设下运行，同时保持理论可靠性。</div>
</details>
</div>
<div class="card">
<div class="title">MorphBoost: Self-Organizing Universal Gradient Boosting with Adaptive Tree Morphing</div>
<div class="meta-line">Authors: Boris Kriuk</div>
<div class="meta-line">First: 2025-11-17T10:54:01+00:00 · Latest: 2025-11-17T10:54:01+00:00</div>
<div class="meta-line">Comments: 8 pages, 5 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.13234v1">Abs</a> · <a href="https://arxiv.org/pdf/2511.13234v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Traditional gradient boosting algorithms employ static tree structures with fixed splitting criteria that remain unchanged throughout training, limiting their ability to adapt to evolving gradient distributions and problem-specific characteristics across different learning stages. This work introduces MorphBoost, a new gradient boosting framework featuring self-organizing tree structures that dynamically morph their splitting behavior during training. The algorithm implements adaptive split functions that evolve based on accumulated gradient statistics and iteration-dependent learning pressures, enabling automatic adjustment to problem complexity. Key innovations include: (1) morphing split criterion combining gradient-based scores with information-theoretic metrics weighted by training progress; (2) automatic problem fingerprinting for intelligent parameter configuration across binary/multiclass/regression tasks; (3) vectorized tree prediction achieving significant computational speedups; (4) interaction-aware feature importance detecting multiplicative relationships; and (5) fast-mode optimization balancing speed and accuracy. Comprehensive benchmarking across 10 diverse datasets against competitive models (XGBoost, LightGBM, GradientBoosting, HistGradientBoosting, ensemble methods) demonstrates that MorphBoost achieves state-of-the-art performance, outperforming XGBoost by 0.84% on average. MorphBoost secured the overall winner position with 4/10 dataset wins (40% win rate) and 6/30 top-3 finishes (20%), while maintaining the lowest variance (σ=0.0948) and highest minimum accuracy across all models, revealing superior consistency and robustness. Performance analysis across difficulty levels shows competitive results on easy datasets while achieving notable improvements on advanced problems due to higher adaptation levels.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MorphBoost：具有自适应树形变的自组织通用梯度提升</div>
<div class="mono" style="margin-top:8px">传统梯度提升算法采用静态树结构，其固定分割准则在整个训练过程中保持不变，限制了其适应不断变化的梯度分布及不同学习阶段特定问题特征的能力。本文提出MorphBoost——一种新型梯度提升框架，其自组织树结构能在训练期间动态调整分割行为。该算法通过基于累积梯度统计量和迭代相关学习压力的自适应分割函数，实现对问题复杂度的自动调节。核心创新包括：(1) 融合梯度评分与训练进度加权的信息论度量的形变分割准则；(2) 面向二分类/多分类/回归任务的智能参数配置自动问题指纹识别；(3) 实现显著计算加速的向量化树预测；(4) 检测乘性关系的交互感知特征重要性；(5) 平衡速度与精度的快速模式优化。在10个异构数据集上与竞争模型（XGBoost、LightGBM、GradientBoosting、HistGradientBoosting及集成方法）的全面基准测试表明，MorphBoost以平均0.84%的优势超越XGBoost达到最优性能。该框架以4/10数据集胜率（40%胜率）和6/30前三名成绩（20%）获得总冠军，同时保持最低方差（σ=0.0948）和所有模型中最高最低准确率，展现出卓越的稳定性和鲁棒性。跨难度级别性能分析显示，其在简单数据集上表现优异，在复杂问题上因更高适应水平实现显著提升。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Traditional gradient boosting methods use static tree structures that cannot adapt to changing data distributions during training, limiting their flexibility. MorphBoost addresses this by introducing self-organizing trees with adaptive split functions that evolve based on gradient statistics and training progress, incorporating gradient-based scores with information-theoretic metrics and automatic problem fingerprinting for various tasks. Experimental results on 10 datasets show MorphBoost outperforms XGBoost by 0.84% on average, achieves the highest win rate and lowest variance, and demonstrates superior robustness, especially on complex problems.</div>
<div class="mono" style="margin-top:8px">传统梯度提升方法采用静态树结构，无法在训练过程中适应数据分布变化，限制了模型灵活性。MorphBoost通过引入自组织树结构解决这一问题，其自适应分裂函数基于梯度统计和训练进度动态演化，结合了梯度评分与信息论度量，并支持跨任务的自动参数配置。在10个数据集上的实验表明，MorphBoost平均性能超越XGBoost达0.84%，取得了最高获胜率和最低方差，展现出卓越的鲁棒性，尤其在复杂问题上因其自适应能力而实现显著提升。</div>
</details>
</div>
<div class="card">
<div class="title">LLM-based Multi-Agent System for Simulating Strategic and Goal-Oriented Data Marketplaces</div>
<div class="meta-line">Authors: Jun Sashihara, Yukihisa Fujita, Kota Nakamura, Masahiro Kuwahara, Teruaki Hayashi</div>
<div class="meta-line">First: 2025-11-17T10:53:04+00:00 · Latest: 2025-11-17T10:53:04+00:00</div>
<div class="meta-line">Comments: 10 pages, 12 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.13233v1">Abs</a> · <a href="https://arxiv.org/pdf/2511.13233v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Data marketplaces, which mediate the purchase and exchange of data from third parties, have attracted growing attention for reducing the cost and effort of data collection while enabling the trading of diverse datasets. However, a systematic understanding of the interactions between market participants, data, and regulations remains limited. To address this gap, we propose a Large Language Model-based Multi-Agent System (LLM-MAS) for data marketplaces. In our framework, buyer and seller agents powered by LLMs operate with explicit objectives and autonomously perform strategic actions, such as planning, searching, purchasing, pricing, and updating data. These agents can reason about market dynamics, forecast future demand, and adjust strategies accordingly. Unlike conventional model-based simulations, which are typically constrained to predefined rules, LLM-MAS supports broader and more adaptive behavior selection through natural language reasoning. We evaluated the framework via simulation experiments using three distribution-based metrics: (1) the number of purchases per dataset, (2) the number of purchases per buyer, and (3) the number of repeated purchases of the same dataset. The results demonstrate that LLM-MAS more faithfully reproduces trading patterns observed in real data marketplaces compared to traditional approaches, and further captures the emergence and evolution of market trends.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于大语言模型的多智能体系统在战略导向型数据市场模拟中的应用</div>
<div class="mono" style="margin-top:8px">数据市场作为第三方数据采购与交换的中介平台，因能降低数据收集成本并促进多样化数据集交易而日益受到关注。然而，目前对市场参与者、数据与监管机制间相互作用的系统性认知仍显不足。为此，我们提出一种基于大语言模型的多智能体系统（LLM-MAS）框架。该框架中，由大语言模型驱动的买卖双方智能体具有明确目标，能自主执行策略性行为——包括规划、搜索、采购、定价及数据更新等。这些智能体可推理市场动态、预测未来需求并相应调整策略。与传统基于模型的仿真方法受限于预设规则不同，LLM-MAS通过自然语言推理支持更广泛、更自适应行为选择。我们采用三项分布指标进行仿真实验评估：（1）单数据集采购量；（2）单买家采购量；（3）同数据集重复采购量。结果表明，相较于传统方法，LLM-MAS能更真实地复现真实数据市场中的交易模式，并有效捕捉市场趋势的涌现与演化过程。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Data marketplaces facilitate third-party data exchange but lack systematic understanding of participant interactions. To address this, the authors propose an LLM-based Multi-Agent System where buyer and seller agents autonomously perform strategic actions like pricing and purchasing through natural language reasoning. Experimental evaluation using distribution metrics shows the system more accurately replicates real marketplace trading patterns and captures trend evolution compared to traditional rule-based simulations.</div>
<div class="mono" style="margin-top:8px">数据市场促进了高效的数据交易，但缺乏对参与者互动的系统性理解。为此，研究者提出了一种基于大语言模型的多智能体系统（LLM-MAS），其中买卖方智能体通过自然语言推理自主执行定价、采购等策略行为。基于分布指标的实验评估表明，与传统规则模拟相比，LLM-MAS更准确地复现了真实市场交易模式，并能捕捉趋势的演变过程。</div>
</details>
</div>
<div class="card">
<div class="title">Informative Communication of Robot Plans</div>
<div class="meta-line">Authors: Michele Persiani, Thomas Hellstrom</div>
<div class="meta-line">First: 2025-11-17T10:44:25+00:00 · Latest: 2025-11-17T10:44:25+00:00</div>
<div class="meta-line">Comments: Conference: PAAMS 2022, 20th International Conference on Practical Applications of Agents and Multi-Agent Systems</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.13226v1">Abs</a> · <a href="https://arxiv.org/pdf/2511.13226v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">When a robot is asked to verbalize its plan it can do it in many ways. For example, a seemingly natural strategy is incremental, where the robot verbalizes its planned actions in plan order. However, an important aspect of this type of strategy is that it misses considerations on what is effectively informative to communicate, because not considering what the user knows prior to explanations. In this paper we propose a verbalization strategy to communicate robot plans informatively, by measuring the information gain that verbalizations have against a second-order theory of mind of the user capturing his prior knowledge on the robot. As shown in our experiments, this strategy allows to understand the robot&#x27;s goal much quicker than by using strategies such as increasing or decreasing plan order. In addition, following our formulation we hint to what is informative and why when a robot communicates its plan.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>机器人计划的信息化传达</div>
<div class="mono" style="margin-top:8px">当要求机器人用语言描述其计划时，它可以通过多种方式实现。例如，看似自然的策略是渐进式描述，即按计划顺序逐条陈述预定动作。然而，此类策略的重要缺陷在于未充分考虑传达内容的信息有效性，因其未考量用户在接收解释前已具备的知识。本文提出一种信息化机器人计划语言描述策略，通过衡量语言描述相对于用户二阶心理理论（包含其对机器人的先验知识）所获得的信息增益。实验表明，相较于递增或递减计划顺序等策略，该方法能更快帮助理解机器人目标。此外，基于我们的模型框架，我们揭示了机器人传达计划时信息有效性的本质及其成因。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the limitation of conventional robot plan verbalization strategies that fail to account for user prior knowledge, leading to ineffective communication. The authors propose a verbalization strategy that measures information gain against a second-order theory of mind model of the user&#x27;s existing knowledge. Experimental results demonstrate that this approach enables users to understand the robot&#x27;s goal significantly faster than incremental or decremental plan-order strategies, while also providing insights into what constitutes informative communication.</div>
<div class="mono" style="margin-top:8px">本研究针对传统机器人计划语言化策略忽略用户先验知识导致沟通低效的问题，提出了一种基于信息增益的优化方法，通过二阶心智理论模型计算用户知识状态下的沟通价值。实验表明，相比递增或递减的计划顺序策略，该方法能显著加快人类对机器人目标的理解速度，同时揭示了构成有效计划沟通的关键要素。</div>
</details>
</div>
<div class="card">
<div class="title">Cost-Effective Communication: An Auction-based Method for Language Agent Interaction</div>
<div class="meta-line">Authors: Yijia Fan, Jusheng Zhang, Kaitong Cai, Jing Yang, Chengpei Tang, Jian Wang, Keze Wang</div>
<div class="meta-line">First: 2025-11-17T10:00:20+00:00 · Latest: 2025-11-17T10:00:20+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.13193v1">Abs</a> · <a href="https://arxiv.org/pdf/2511.13193v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multi-agent systems (MAS) built on large language models (LLMs) often suffer from inefficient &quot;free-for-all&quot; communication, leading to exponential token costs and low signal-to-noise ratios that hinder their practical deployment. We challenge the notion that more communication is always beneficial, hypothesizing instead that the core issue is the absence of resource rationality. We argue that &quot;free&quot; communication, by ignoring the principle of scarcity, inherently breeds inefficiency and unnecessary expenses. To address this, we introduce the Dynamic Auction-based Language Agent (DALA), a novel framework that treats communication bandwidth as a scarce and tradable resource. Specifically, our DALA regards inter-agent communication as a centralized auction, where agents learn to bid for the opportunity to speak based on the predicted value density of their messages. Thus, our DALA intrinsically encourages agents to produce concise, informative messages while filtering out low-value communication. Extensive and comprehensive experiments demonstrate that our economically-driven DALA achieves new state-of-the-art performance across seven challenging reasoning benchmarks, including 84.32% on MMLU and a 91.21% pass@1 rate on HumanEval. Note that this is accomplished with remarkable efficiency, i.e., our DALA uses only 6.25 million tokens, a fraction of the resources consumed by current state-of-the-art methods on GSM8K. Further analysis reveals that our DALA cultivates the emergent skill of strategic silence, effectively adapting its communication strategies from verbosity to silence in a dynamical manner via resource constraints.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>成本效益通信：一种基于拍卖的语言智能体交互方法</div>
<div class="mono" style="margin-top:8px">基于大语言模型的多智能体系统常因低效的&#x27;自由通信&#x27;导致令牌消耗指数级增长及信噪比低下，制约实际应用。我们质疑&#x27;更多通信必然有益&#x27;的观点，提出核心问题在于缺乏资源理性——忽视稀缺性原则的&#x27;免费&#x27;通信必然导致低效与冗余开销。为此，我们提出动态拍卖语言智能体框架，将通信带宽视为可交易的稀缺资源。该框架将智能体间通信建模为集中式拍卖，智能体通过学习基于消息价值密度进行发言权竞价，从而内生激励生成简洁高效的信息并过滤低价值通信。大量实验表明，我们的经济驱动框架在七大推理基准测试中刷新最优性能记录，包括MMLU 84.32%准确率和HumanEval 91.21%通过率，且仅消耗625万令牌（仅为当前最优方法在GSM8K任务资源消耗的零头）。深入分析揭示，该框架培育出&#x27;策略性沉默&#x27;的涌现能力，通过资源约束动态调整通信策略，实现从冗言到静默的自适应转换。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the inefficiency of multi-agent systems built on large language models, where unrestricted communication leads to high token costs and low signal-to-noise ratios. The authors propose the Dynamic Auction-based Language Agent (DALA), which treats communication bandwidth as a scarce resource and implements a centralized auction mechanism where agents bid to speak based on message value density. Experimental results show DALA achieves state-of-the-art performance across seven reasoning benchmarks, including 84.32% on MMLU and 91.21% pass@1 on HumanEval, while using only 6.25 million tokens on GSM8K—significantly fewer than existing methods—and demonstrates emergent strategic silence behavior through resource constraints.</div>
<div class="mono" style="margin-top:8px">基于大语言模型的多智能体系统常因通信效率低下导致高昂的令牌成本和低信噪比，这促使研究需解决资源理性交互问题。为此，作者提出动态拍卖语言智能体（DALA）框架，将通信带宽视为稀缺资源，采用集中拍卖机制使智能体根据消息预测价值密度竞标发言权，从而鼓励简洁高效的信息交换。实验结果表明，DALA在七个推理基准测试中达到最先进性能，包括MMLU的84.32%和HumanEval的91.21%通过率，同时在GSM8K上仅使用625万令牌，显著提升效率并培养出策略性沉默的通信能力。</div>
</details>
</div>
<div class="card">
<div class="title">DiffFP: Learning Behaviors from Scratch via Diffusion-based Fictitious Play</div>
<div class="meta-line">Authors: Akash Karthikeyan, Yash Vardhan Pant</div>
<div class="meta-line">Venue: IJCAI 2025</div>
<div class="meta-line">First: 2025-11-17T09:48:29+00:00 · Latest: 2025-11-17T09:48:29+00:00</div>
<div class="meta-line">Comments: Initial results presented at the IJCAI 2025 Workshop on User-Aligned Assessment of Adaptive AI Systems. Project page: https://aku02.github.io/projects/difffp/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.13186v1">Abs</a> · <a href="https://arxiv.org/pdf/2511.13186v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://aku02.github.io/projects/difffp/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Self-play reinforcement learning has demonstrated significant success in learning complex strategic and interactive behaviors in competitive multi-agent games. However, achieving such behaviors in continuous decision spaces remains challenging. Ensuring adaptability and generalization in self-play settings is critical for achieving competitive performance in dynamic multi-agent environments. These challenges often cause methods to converge slowly or fail to converge at all to a Nash equilibrium, making agents vulnerable to strategic exploitation by unseen opponents. To address these challenges, we propose DiffFP, a fictitious play (FP) framework that estimates the best response to unseen opponents while learning a robust and multimodal behavioral policy. Specifically, we approximate the best response using a diffusion policy that leverages generative modeling to learn adaptive and diverse strategies. Through empirical evaluation, we demonstrate that the proposed FP framework converges towards $ε$-Nash equilibria in continuous- space zero-sum games. We validate our method on complex multi-agent environments, including racing and multi-particle zero-sum games. Simulation results show that the learned policies are robust against diverse opponents and outperform baseline reinforcement learning policies. Our approach achieves up to 3$\times$ faster convergence and 30$\times$ higher success rates on average against RL-based baselines, demonstrating its robustness to opponent strategies and stability across training iterations</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>DiffFP：基于扩散虚拟博弈的从零开始行为学习</div>
<div class="mono" style="margin-top:8px">自博弈强化学习在竞争性多智能体游戏中已成功实现复杂策略与交互行为的学习，但在连续决策空间中实现此类行为仍具挑战。确保自博弈环境中的适应性与泛化能力对于动态多智能体环境中的竞争优势至关重要。现有方法常因收敛缓慢或无法收敛至纳什均衡，导致智能体易受未知对手策略利用。为此，我们提出DiffFP虚拟博弈框架，通过扩散策略利用生成模型学习自适应、多样化的策略来逼近最优响应。实证研究表明，该框架能在连续空间零和博弈中收敛至$ε$-纳什均衡。我们在竞速游戏与多粒子零和博弈等复杂环境中验证了该方法，实验表明所学策略能有效应对多样对手，其收敛速度最高提升3倍，平均成功率较基线强化学习方法提高30倍，展现出卓越的策略鲁棒性与训练稳定性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Self-play reinforcement learning struggles to achieve robust and adaptive behaviors in continuous multi-agent games, often converging slowly or failing to reach Nash equilibria, which leaves agents vulnerable to exploitation by unseen opponents. To address this, DiffFP introduces a fictitious play framework that approximates the best response using a diffusion policy, leveraging generative modeling to learn adaptive and multimodal strategies. Experimental results in continuous zero-sum games show that DiffFP converges toward ε-Nash equilibria, outperforms baseline reinforcement learning policies with up to 3× faster convergence and 30× higher success rates on average, and demonstrates robustness against diverse opponents.</div>
<div class="mono" style="margin-top:8px">自博弈强化学习在连续多智能体游戏中难以实现鲁棒和自适应行为，常因收敛缓慢或无法达到纳什均衡而面临策略利用风险。为此，DiffFP提出了一种虚拟博弈框架，通过扩散策略利用生成建模来学习自适应、多模态的最佳响应策略。在连续零和博弈环境中的实验表明，该方法能收敛至ε-纳什均衡，相比基线方法收敛速度提升最高3倍、成功率平均提高30倍，且对多样对手策略表现出强鲁棒性。</div>
</details>
</div>
<div class="card">
<div class="title">Real-time distortion prediction in metallic additive manufacturing via a physics-informed neural operator approach</div>
<div class="meta-line">Authors: Mingxuan Tian, Haochen Mu, Donghong Ding, Mengjiao Li, Yuhan Ding, Jianping Zhao</div>
<div class="meta-line">First: 2025-11-17T09:37:04+00:00 · Latest: 2025-11-17T09:37:04+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.13178v1">Abs</a> · <a href="https://arxiv.org/pdf/2511.13178v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">With the development of digital twins and smart manufacturing systems, there is an urgent need for real-time distortion field prediction to control defects in metal Additive Manufacturing (AM). However, numerical simulation methods suffer from high computational cost, long run-times that prevent real-time use, while conventional Machine learning (ML) models struggle to extract spatiotemporal features for long-horizon prediction and fail to decouple thermo-mechanical fields. This paper proposes a Physics-informed Neural Operator (PINO) to predict z and y-direction distortion for the future 15 s. Our method, Physics-informed Deep Operator Network-Recurrent Neural Network (PIDeepONet-RNN) employs trunk and branch network to process temperature history and encode distortion fields, respectively, enabling decoupling of thermo-mechanical responses. By incorporating the heat conduction equation as a soft constraint, the model ensures physical consistency and suppresses unphysical artifacts, thereby establishing a more physically consistent mapping between the thermal history and distortion. This is important because such a basis function, grounded in physical laws, provides a robust and interpretable foundation for predictions. The proposed models are trained and tested using datasets generated from experimentally validated Finite Element Method (FEM). Evaluation shows that the model achieves high accuracy, low error accumulation, time efficiency. The max absolute errors in the z and y-directions are as low as 0.9733 mm and 0.2049 mm, respectively. The error distribution shows high errors in the molten pool but low gradient norms in the deposited and key areas. The performance of PINO surrogate model highlights its potential for real-time long-horizon physics field prediction in controlling defects.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于物理信息神经算子方法的金属增材制造实时变形预测</div>
<div class="mono" style="margin-top:8px">随着数字孪生与智能制造系统的发展，金属增材制造领域亟需实现实时变形场预测以控制缺陷。然而，数值模拟方法存在计算成本高、耗时长等问题难以满足实时需求，传统机器学习模型则难以提取时空特征进行长时程预测，且无法解耦热力耦合场。本文提出物理信息神经算子方法，用于预测未来15秒内z向与y向的变形场。我们提出的物理信息深度算子网络-循环神经网络通过分支网络处理温度历史、主干网络编码变形场，实现了热力响应的解耦。通过将热传导方程作为软约束融入模型，既保证了物理一致性又抑制了非物理伪影，从而建立了热历史与变形场之间更具物理一致性的映射关系。这种基于物理定律的基函数为预测提供了鲁棒性强、可解释性高的理论基础。所提模型采用经实验验证的有限元法生成数据集进行训练测试，评估表明该模型具有精度高、误差累积低、时效性强等特点：z向与y向最大绝对误差分别低至0.9733毫米和0.2049毫米。误差分布显示熔池区域误差较高，但沉积区域与关键区域的梯度范数保持较低水平。该代理模型的优异性能彰显了其在缺陷控制领域实现实时长时程物理场预测的应用潜力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the need for real-time distortion prediction in metal additive manufacturing to control defects, as traditional numerical simulations are computationally expensive and conventional machine learning models fail to capture spatiotemporal features and decouple thermo-mechanical fields. The proposed method, Physics-informed Deep Operator Network-Recurrent Neural Network (PIDeepONet-RNN), uses trunk and branch networks to process temperature history and encode distortion fields, incorporating the heat conduction equation as a soft constraint to ensure physical consistency. Experimental results on datasets from validated Finite Element Method simulations show the model achieves high accuracy with maximum absolute errors of 0.9733 mm in the z-direction and 0.2049 mm in the y-direction, low error accumulation, and efficient performance, demonstrating its potential for real-time long-horizon physics field prediction.</div>
<div class="mono" style="margin-top:8px">本研究针对金属增材制造中实时预测变形以控制缺陷的需求，克服了数值模拟计算成本高、传统机器学习模型难以提取时空特征和解耦热力场的问题。提出的物理信息神经算子方法采用主干和分支网络分别处理温度历史和编码变形场，并通过热传导方程作为软约束确保物理一致性。基于有限元方法数据集的实验结果表明，该方法在z和y方向的最大绝对误差分别低至0.9733毫米和0.2049毫米，误差累积低，在沉积区域表现良好，尽管熔池区域误差较高。</div>
</details>
</div>
<div class="card">
<div class="title">EcoAgent: An Efficient Device-Cloud Collaborative Multi-Agent Framework for Mobile Automation</div>
<div class="meta-line">Authors: Biao Yi, Xavier Hu, Yurun Chen, Shengyu Zhang, Hongxia Yang, Fan Wu</div>
<div class="meta-line">Venue: AAAI 2026</div>
<div class="meta-line">First: 2025-05-08T17:31:20+00:00 · Latest: 2025-11-17T09:12:00+00:00</div>
<div class="meta-line">Comments: Accepted by AAAI 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.05440v3">Abs</a> · <a href="https://arxiv.org/pdf/2505.05440v3">PDF</a> · <a href="https://github.com/Yi-Biao/EcoAgent">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">To tackle increasingly complex tasks, recent research on mobile agents has shifted towards multi-agent collaboration. Current mobile multi-agent systems are primarily deployed in the cloud, leading to high latency and operational costs. A straightforward idea is to deploy a device-cloud collaborative multi-agent system, which is nontrivial, as directly extending existing systems introduces new challenges: (1) reliance on cloud-side verification requires uploading mobile screenshots, compromising user privacy; and (2) open-loop cooperation lacking device-to-cloud feedback, underutilizing device resources and increasing latency. To overcome these limitations, we propose EcoAgent, a closed-loop device-cloud collaborative multi-agent framework designed for privacy-aware, efficient, and responsive mobile automation. EcoAgent integrates a novel reasoning approach, Dual-ReACT, into the cloud-based Planning Agent, fully exploiting cloud reasoning to compensate for limited on-device capacity, thereby enabling device-side verification and lightweight feedback. Furthermore, the device-based Observation Agent leverages a Pre-understanding Module to summarize screen content into concise textual descriptions, significantly reducing token usage and device-cloud communication overhead while preserving privacy. Experiments on AndroidWorld demonstrate that EcoAgent matches the task success rates of fully cloud-based agents, while reducing resource consumption and response latency. Our project is available here: https://github.com/Yi-Biao/EcoAgent.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>EcoAgent：一种高效的端云协同移动自动化多智能体框架</div>
<div class="mono" style="margin-top:8px">为应对日益复杂的任务，移动智能体研究已转向多智能体协作。现有移动多智能体系统主要部署于云端，导致高延迟与运营成本。直接部署端云协同系统面临新挑战：（1）依赖云端验证需上传屏幕截图，危及用户隐私；（2）开环协作缺乏端到云反馈，未能充分利用设备资源且增加延迟。为此我们提出EcoAgent——面向隐私保护、高效响应的闭环端云协同多智能体框架。该框架将新型推理方法Dual-ReACT集成至云端规划智能体，充分发挥云端推理能力以弥补终端算力限制，实现终端验证与轻量反馈。基于设备的观测智能体通过预理解模块将屏幕内容转化为简洁文本描述，显著降低令牌用量与通信开销的同时保护隐私。AndroidWorld实验表明，EcoAgent在保持与全云端方案相当任务成功率的同时，有效降低资源消耗与响应延迟。项目地址：https://github.com/Yi-Biao/EcoAgent</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the high latency and privacy risks of cloud-only mobile multi-agent systems, this study introduces EcoAgent, a device-cloud collaborative framework that employs a Dual-ReACT reasoning method for cloud-based planning and a Pre-understanding Module on devices to summarize screen content into text, reducing communication overhead. Experimental results on AndroidWorld show that EcoAgent achieves task success rates comparable to fully cloud-based agents while significantly lowering resource consumption and response latency.</div>
<div class="mono" style="margin-top:8px">为解决纯云端移动多智能体系统的高延迟和隐私问题，本研究提出EcoAgent，一种设备-云协同框架，采用Dual-ReACT推理方法进行云端规划，并在设备端使用预理解模块将屏幕内容概括为文本以降低通信开销。在AndroidWorld上的实验表明，EcoAgent在任务成功率上与全云端智能体相当，同时显著减少了资源消耗和响应延迟。</div>
</details>
</div>
<div class="card">
<div class="title">Agent-Oriented Visual Programming for the Web of Things</div>
<div class="meta-line">Authors: Samuele Burattini, Alessandro Ricci, Simon Mayer, Danai Vachtsevanou, Jeremy Lemee, Andrei Ciortea, Angelo Croatti</div>
<div class="meta-line">First: 2025-11-17T09:06:00+00:00 · Latest: 2025-11-17T09:06:00+00:00</div>
<div class="meta-line">Comments: Accepted and presented at the 10th International Workshop on Engineering Multi-Agent Systems (EMAS 2022), 9-10 May 2022, Auckland, New Zealand</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.13158v1">Abs</a> · <a href="https://arxiv.org/pdf/2511.13158v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In this paper we introduce and discuss an approach for multi-agent-oriented visual programming. This aims at enabling individuals without programming experience but with knowledge in specific target domains to design and (re)configure autonomous software. We argue that, compared to procedural programming, it should be simpler for users to create programs when agent abstractions are employed. The underlying rationale is that these abstractions, and specifically the belief-desire-intention architecture that is aligned with human practical reasoning, match more closely with people&#x27;s everyday experience in interacting with other agents and artifacts in the real world. On top of this, we designed and implemented a visual programming system for agents that hides the technicalities of agent-oriented programming using a blocks-based visual development environment that is built on the JaCaMo platform. To further validate the proposed solution, we integrate the Web of Things (WoT) to let users create autonomous behaviour on top of physical mashups of devices, following the trends in industrial end-user programming. Finally, we report on a pilot user study where we verified that novice users are indeed able to make use of this development environment to create multi-agent systems to solve simple automation tasks.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向智能体的物联网可视化编程</div>
<div class="mono" style="margin-top:8px">本文提出并探讨了一种面向多智能体的可视化编程方法，旨在使具有特定领域知识但无编程经验的用户能够设计与（重新）配置自主软件。相较于过程式编程，我们认为采用智能体抽象可使用户更简易地创建程序，其核心理念在于这类抽象——特别是符合人类实践推理的信念-愿望-意图架构——更贴近人们在现实世界中与其他智能体及物件交互的日常经验。基于此，我们设计并实现了基于JaCaMo平台的可视化智能体编程系统，通过模块化视觉开发环境隐藏面向智能体编程的技术细节。为验证方案可行性，我们集成物联网技术，允许用户在物理设备混搭基础上创建自主行为，顺应工业端用户编程趋势。最后通过初步用户研究证实，新手用户能利用该开发环境构建多智能体系统以完成简单自动化任务。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research aims to enable non-programmers with domain expertise to design and reconfigure autonomous software by leveraging agent abstractions, which align with human practical reasoning through the belief-desire-intention architecture. The method involves developing a visual programming system using a blocks-based environment built on the JaCaMo platform, integrated with the Web of Things to support physical device mashups for autonomous behavior creation. Experimental results from a pilot user study confirm that novice users successfully utilized this environment to build multi-agent systems for simple automation tasks.</div>
<div class="mono" style="margin-top:8px">本研究旨在通过采用符合人类实践推理的智能体抽象，使具备领域知识的非编程人员能够设计自主软件。方法基于JaCaMo平台开发了可视化编程系统，采用积木式环境简化智能体导向编程，并集成万维物联网以实现物理设备自动化。初步用户实验结果表明，新手用户能够成功构建多智能体系统来完成简单的自动化任务。</div>
</details>
</div>
<div class="card">
<div class="title">Personalized Federated Learning with Bidirectional Communication Compression via One-Bit Random Sketching</div>
<div class="meta-line">Authors: Jiacheng Cheng, Xu Zhang, Guanghui Qiu, Yifang Zhang, Yinchuan Li, Kaiyuan Feng</div>
<div class="meta-line">Venue: AAAI 2026</div>
<div class="meta-line">First: 2025-11-17T08:55:22+00:00 · Latest: 2025-11-17T08:55:22+00:00</div>
<div class="meta-line">Comments: Accepted in AAAI 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.13144v1">Abs</a> · <a href="https://arxiv.org/pdf/2511.13144v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Federated Learning (FL) enables collaborative training across decentralized data, but faces key challenges of bidirectional communication overhead and client-side data heterogeneity. To address communication costs while embracing data heterogeneity, we propose pFed1BS, a novel personalized federated learning framework that achieves extreme communication compression through one-bit random sketching. In personalized FL, the goal shifts from training a single global model to creating tailored models for each client. In our framework, clients transmit highly compressed one-bit sketches, and the server aggregates and broadcasts a global one-bit consensus. To enable effective personalization, we introduce a sign-based regularizer that guides local models to align with the global consensus while preserving local data characteristics. To mitigate the computational burden of random sketching, we employ the Fast Hadamard Transform for efficient projection. Theoretical analysis guarantees that our algorithm converges to a stationary neighborhood of the global potential function. Numerical simulations demonstrate that pFed1BS substantially reduces communication costs while achieving competitive performance compared to advanced communication-efficient FL algorithms.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于单比特随机草图的双向通信压缩个性化联邦学习</div>
<div class="mono" style="margin-top:8px">联邦学习(FL)支持分布式数据协同训练，但面临双向通信开销与客户端数据异构性两大挑战。为降低通信成本并兼容数据异构性，我们提出pFed1BS新型个性化联邦学习框架，通过单比特随机草图实现极致通信压缩。在个性化FL中，目标从训练单一全局模型转变为为每个客户端定制专属模型。本框架中，客户端传输高度压缩的单比特草图，服务器聚合并广播全局单比特共识。为实现有效个性化，我们引入基于符号的正则化器，指导本地模型在保持数据特性的同时与全局共识对齐。为减轻随机草图计算负担，采用快速哈达玛变换实现高效投影。理论分析证明算法能收敛至全局势函数的稳定邻域。数值模拟表明，相较于先进高效通信FL算法，pFed1BS在显著降低通信成本的同时保持竞争优势。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Federated Learning faces challenges of high bidirectional communication costs and client data heterogeneity. To address these issues, this work proposes pFed1BS, a personalized federated learning framework that employs one-bit random sketching for extreme communication compression, where clients send compressed one-bit sketches and the server aggregates a global one-bit consensus. A sign-based regularizer is introduced to align local models with the global consensus while preserving local data characteristics, and Fast Hadamard Transform is used to reduce computational overhead. Theoretical analysis confirms convergence to a stationary neighborhood, and experiments show that pFed1BS significantly reduces communication costs while achieving competitive performance compared to state-of-the-art communication-efficient FL methods.</div>
<div class="mono" style="margin-top:8px">本研究针对联邦学习中的双向通信开销高和客户端数据异构性双重挑战，提出了pFed1BS个性化联邦学习框架，通过一位随机草图实现极致的通信压缩。方法包括客户端传输压缩的一位草图、服务器聚合全局一位共识，以及使用基于符号的正则化器在保持本地数据特性的同时对齐全局更新，并借助快速哈达玛变换提升计算效率。实验结果表明，pFed1BS在显著降低通信成本的同时，性能与先进的通信高效联邦学习算法相当，并得到理论收敛性保证。</div>
</details>
</div>
<div class="card">
<div class="title">Conditional Diffusion Model for Multi-Agent Dynamic Task Decomposition</div>
<div class="meta-line">Authors: Yanda Zhu, Yuanyang Zhu, Daoyi Dong, Caihua Chen, Chunlin Chen</div>
<div class="meta-line">Venue: AAAI 2026</div>
<div class="meta-line">First: 2025-11-17T08:46:31+00:00 · Latest: 2025-11-17T08:46:31+00:00</div>
<div class="meta-line">Comments: AAAI 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.13137v1">Abs</a> · <a href="https://arxiv.org/pdf/2511.13137v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Task decomposition has shown promise in complex cooperative multi-agent reinforcement learning (MARL) tasks, which enables efficient hierarchical learning for long-horizon tasks in dynamic and uncertain environments. However, learning dynamic task decomposition from scratch generally requires a large number of training samples, especially exploring the large joint action space under partial observability. In this paper, we present the Conditional Diffusion Model for Dynamic Task Decomposition (C$\text{D}^\text{3}$T), a novel two-level hierarchical MARL framework designed to automatically infer subtask and coordination patterns. The high-level policy learns subtask representation to generate a subtask selection strategy based on subtask effects. To capture the effects of subtasks on the environment, C$\text{D}^\text{3}$T predicts the next observation and reward using a conditional diffusion model. At the low level, agents collaboratively learn and share specialized skills within their assigned subtasks. Moreover, the learned subtask representation is also used as additional semantic information in a multi-head attention mixing network to enhance value decomposition and provide an efficient reasoning bridge between individual and joint value functions. Experimental results on various benchmarks demonstrate that C$\text{D}^\text{3}$T achieves better performance than existing baselines.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>条件扩散模型在多智能体动态任务分解中的应用</div>
<div class="mono" style="margin-top:8px">任务分解在复杂协作多智能体强化学习任务中展现出潜力，可实现动态不确定环境下长周期任务的高效分层学习。然而从零开始学习动态任务分解通常需要大量训练样本，尤其在部分可观测条件下探索庞大的联合动作空间时。本文提出动态任务分解条件扩散模型（C$\text{D}^\text{3}$T），这是一种新颖的两层分层多智能体强化学习框架，能自动推断子任务与协作模式。高层策略通过学习子任务表征生成基于子任务效用的选择策略，通过条件扩散模型预测下一观测值与奖励以捕捉子任务对环境的影响。底层智能体在分配的子任务中协作学习并共享专项技能。此外，学得的子任务表征作为多头注意力混合网络的语义信息，既增强价值分解效能，又为个体与联合价值函数间构建高效推理桥梁。多基准测试表明C$\text{D}^\text{3}$T性能优于现有基线方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the challenge of learning dynamic task decomposition in cooperative multi-agent reinforcement learning, which typically requires extensive training samples due to large joint action spaces under partial observability. The proposed Conditional Diffusion Model for Dynamic Task Decomposition (C$\text{D}^\text{3}$T) introduces a two-level hierarchical framework where a high-level policy learns subtask representations using a conditional diffusion model to predict environmental effects, while low-level agents collaboratively develop specialized skills within assigned subtasks. Experimental evaluations across multiple benchmarks show that C$\text{D}^\text{3}$T outperforms existing baseline methods in performance metrics.</div>
<div class="mono" style="margin-top:8px">本研究针对合作多智能体强化学习中动态任务分解的学习挑战，该问题在部分可观测性下因联合动作空间庞大通常需要大量训练样本。提出的条件扩散动态任务分解模型（C$\text{D}^\text{3}$T）采用双层分层框架：高层策略通过条件扩散模型学习子任务表示以预测环境效应，底层智能体在子任务内协作学习专项技能；子任务表示还通过多头注意力网络增强价值分解。在多基准测试中的实验结果表明，C$\text{D}^\text{3}$T性能优于现有基线方法。</div>
</details>
</div>
<div class="card">
<div class="title">Surrogate Modeling and Explainable Artificial Intelligence for Complex Systems: A Workflow for Automated Simulation Exploration</div>
<div class="meta-line">Authors: Paul Saves, Pramudita Satria Palar, Muhammad Daffa Robani, Nicolas Verstaevel, Moncef Garouani, Julien Aligon, Benoit Gaudou, Koji Shimoyama, Joseph Morlier</div>
<div class="meta-line">First: 2025-10-19T07:55:52+00:00 · Latest: 2025-11-17T08:38:34+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.16742v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.16742v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Complex systems are increasingly explored through simulation-driven engineering workflows that combine physics-based and empirical models with optimization and analytics. Despite their power, these workflows face two central obstacles: (1) high computational cost, since accurate exploration requires many expensive simulator runs; and (2) limited transparency and reliability when decisions rely on opaque blackbox components. We propose a workflow that addresses both challenges by training lightweight emulators on compact designs of experiments that (i) provide fast, low-latency approximations of expensive simulators, (ii) enable rigorous uncertainty quantification, and (iii) are adapted for global and local Explainable Artificial Intelligence (XAI) analyses. This workflow unifies every simulation-based complex-system analysis tool, ranging from engineering design to agent-based models for socio-environmental understanding. In this paper, we proposea comparative methodology and practical recommendations for using surrogate-based explainability tools within the proposed workflow. The methodology supports continuous and categorical inputs, combines global-effect and uncertainty analyses with local attribution, and evaluates the consistency of explanations across surrogate models, thereby diagnosing surrogate adequacy and guiding further data collection or model refinement. We demonstrate the approach on two contrasting case studies: a multidisciplinary design analysis of a hybrid-electric aircraft and an agent-based model of urban segregation. Results show that the surrogate model and XAI coupling enables large-scale exploration in seconds, uncovers nonlinear interactions and emergent behaviors, identifies key design and policy levers, and signals regions where surrogates require more data or alternative architectures.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向复杂系统的代理建模与可解释人工智能：自动化仿真探索工作流</div>
<div class="mono" style="margin-top:8px">复杂系统正日益通过结合物理模型与经验模型的仿真驱动工程工作流进行研究，这些工作流融合了优化与分析技术。尽管功能强大，此类工作流面临两大核心挑战：(1) 高昂的计算成本，因为精确探索需要大量昂贵的仿真运行；(2) 依赖不透明黑箱组件时决策透明度与可靠性受限。我们提出一种通过紧凑实验设计训练轻量化代理模型的工作流，该方案能够：(i) 提供快速低延迟的近似仿真，(ii) 实现严格的不确定性量化，(iii) 适配全局与局部可解释人工智能分析。该工作流统一了从工程设计到社会环境理解的基于代理的建模等所有仿真驱动的复杂系统分析工具。本文提出比较方法论与实践建议，支持在连续型和分类型输入中结合全局效应与不确定性分析，通过局部归因评估不同代理模型解释的一致性，从而诊断代理模型充分性并指导数据收集或模型优化。通过混合动力飞机多学科设计分析与城市隔离代理模型两个对比案例验证，结果表明代理模型与可解释人工智能的耦合能在秒级完成大规模探索，揭示非线性相互作用与涌现行为，识别关键设计与政策杠杆，并指示需要补充数据或改进架构的代理区域。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the dual challenges of high computational cost and limited transparency in simulation-driven engineering workflows for complex systems. The proposed method trains lightweight surrogate models on compact experimental designs to approximate expensive simulators, enabling fast exploration, uncertainty quantification, and explainable AI analyses for both global and local interpretations. Experimental results from case studies on hybrid-electric aircraft design and urban segregation modeling demonstrate that the approach enables rapid large-scale exploration, uncovers nonlinear interactions and key system levers, and identifies regions requiring improved surrogate modeling.</div>
<div class="mono" style="margin-top:8px">本研究针对复杂系统仿真驱动工程工作流面临的高计算成本和有限透明度双重挑战，提出通过紧凑实验设计训练轻量级代理模型的方法。该方法能够提供快速近似计算、实现不确定性量化，并支持全局与局部可解释人工智能分析。在混合动力飞机设计和城市隔离建模的案例研究中，该方法实现了秒级大规模探索，揭示了非线性相互作用与关键参数，并识别出需要补充数据或模型改进的区域。</div>
</details>
</div>
<div class="card">
<div class="title">Departures: Distributional Transport for Single-Cell Perturbation Prediction with Neural Schrödinger Bridges</div>
<div class="meta-line">Authors: Changxi Chi, Yufei Huang, Jun Xia, Jiangbin Zheng, Yunfan Liu, Zelin Zang, Stan Z. Li</div>
<div class="meta-line">First: 2025-11-17T08:27:13+00:00 · Latest: 2025-11-17T08:27:13+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.13124v1">Abs</a> · <a href="https://arxiv.org/pdf/2511.13124v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Predicting single-cell perturbation outcomes directly advances gene function analysis and facilitates drug candidate selection, making it a key driver of both basic and translational biomedical research. However, a major bottleneck in this task is the unpaired nature of single-cell data, as the same cell cannot be observed both before and after perturbation due to the destructive nature of sequencing. Although some neural generative transport models attempt to tackle unpaired single-cell perturbation data, they either lack explicit conditioning or depend on prior spaces for indirect distribution alignment, limiting precise perturbation modeling. In this work, we approximate Schrödinger Bridge (SB), which defines stochastic dynamic mappings recovering the entropy-regularized optimal transport (OT), to directly align the distributions of control and perturbed single-cell populations across different perturbation conditions. Unlike prior SB approximations that rely on bidirectional modeling to infer optimal source-target sample coupling, we leverage Minibatch-OT based pairing to avoid such bidirectional inference and the associated ill-posedness of defining the reverse process. This pairing directly guides bridge learning, yielding a scalable approximation to the SB. We approximate two SB models, one modeling discrete gene activation states and the other continuous expression distributions. Joint training enables accurate perturbation modeling and captures single-cell heterogeneity. Experiments on public genetic and drug perturbation datasets show that our model effectively captures heterogeneous single-cell responses and achieves state-of-the-art performance.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>离群：基于神经薛定谔桥的单细胞扰动预测分布迁移方法</div>
<div class="mono" style="margin-top:8px">单细胞扰动结果预测直接推动基因功能分析并促进候选药物筛选，成为基础与转化生物医学研究的关键驱动力。然而该任务的主要瓶颈在于单细胞数据的非配对特性——由于测序的破坏性，同一细胞无法在扰动前后被重复观测。尽管部分神经生成迁移模型尝试处理非配对单细胞扰动数据，但它们或缺乏显式条件机制，或依赖先验空间进行间接分布对齐，限制了精确的扰动建模。本研究通过逼近薛定谔桥——定义恢复熵正则化最优传输的随机动态映射——直接对齐不同扰动条件下对照组与扰动组的单细胞群体分布。与依赖双向建模推断最优源-目标样本耦合的现有SB近似方法不同，我们利用基于最小批次最优传输的配对策略规避双向推断及反向过程定义的不适定性。这种配对直接指导桥梁学习，形成可扩展的SB近似方案。我们构建了两个SB模型：分别模拟离散基因激活状态和连续表达分布。联合训练实现了精准扰动建模并捕获单细胞异质性。在公共遗传与药物扰动数据集上的实验表明，我们的模型有效捕捉异质性单细胞响应并达到最先进性能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the challenge of predicting single-cell perturbation outcomes from unpaired data, where the same cell cannot be observed both before and after perturbation due to destructive sequencing. The method approximates the Schrödinger Bridge using Minibatch-OT based pairing to directly align control and perturbed population distributions, avoiding bidirectional inference and enabling scalable modeling of both discrete gene states and continuous expression distributions. Experimental results on genetic and drug perturbation datasets demonstrate that the model effectively captures heterogeneous cellular responses and achieves state-of-the-art performance.</div>
<div class="mono" style="margin-top:8px">本研究针对单细胞扰动预测中因测序破坏性导致无法配对观测同一细胞的问题，提出了一种基于Minibatch-OT配对的薛定谔桥近似方法，直接对齐对照组与扰动组的分布，避免了双向推理的局限性。该方法通过联合训练离散基因激活状态和连续表达分布模型，实现了可扩展的扰动建模。在公开遗传与药物扰动数据集上的实验表明，该模型能有效捕捉单细胞异质性响应，并达到了最先进的预测性能。</div>
</details>
</div>
<div class="card">
<div class="title">Extracting Events Like Code: A Multi-Agent Programming Framework for Zero-Shot Event Extraction</div>
<div class="meta-line">Authors: Quanjiang Guo, Sijie Wang, Jinchuan Zhang, Ben Zhang, Zhao Kang, Ling Tian, Ke Yan</div>
<div class="meta-line">Venue: AAAI 2026 Oral</div>
<div class="meta-line">First: 2025-11-17T08:17:15+00:00 · Latest: 2025-11-17T08:17:15+00:00</div>
<div class="meta-line">Comments: 11 pages, 5 figures, accepted by AAAI 2026 (Oral)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.13118v1">Abs</a> · <a href="https://arxiv.org/pdf/2511.13118v1">PDF</a> · <a href="https://github.com/UESTC-GQJ/Agent-Event-Coder">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Zero-shot event extraction (ZSEE) remains a significant challenge for large language models (LLMs) due to the need for complex reasoning and domain-specific understanding. Direct prompting often yields incomplete or structurally invalid outputs--such as misclassified triggers, missing arguments, and schema violations. To address these limitations, we present Agent-Event-Coder (AEC), a novel multi-agent framework that treats event extraction like software engineering: as a structured, iterative code-generation process. AEC decomposes ZSEE into specialized subtasks--retrieval, planning, coding, and verification--each handled by a dedicated LLM agent. Event schemas are represented as executable class definitions, enabling deterministic validation and precise feedback via a verification agent. This programming-inspired approach allows for systematic disambiguation and schema enforcement through iterative refinement. By leveraging collaborative agent workflows, AEC enables LLMs to produce precise, complete, and schema-consistent extractions in zero-shot settings. Experiments across five diverse domains and six LLMs demonstrate that AEC consistently outperforms prior zero-shot baselines, showcasing the power of treating event extraction like code generation. The code and data are released on https://github.com/UESTC-GQJ/Agent-Event-Coder.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>像编写代码一样提取事件：一种用于零样本事件提取的多智能体编程框架</div>
<div class="mono" style="margin-top:8px">零样本事件提取对大型语言模型仍构成重大挑战，因其需要复杂推理和领域特定理解。直接提示常产生不完整或结构无效的输出——如错误分类的触发词、缺失参数及模式违规。为突破这些局限，我们提出Agent-Event-Coder创新多智能体框架，将事件提取视作软件工程：一个结构化、迭代式的代码生成过程。该框架将零样本事件提取分解为检索、规划、编码与验证四个专项子任务，分别由专用大语言模型智能体处理。事件模式被表示为可执行的类定义，通过验证智能体实现确定性校验与精准反馈。这种编程启发的方案通过迭代优化实现系统化消歧与模式强化。借助协同智能体工作流，该框架使大语言模型在零样本环境下能生成精确、完整且模式一致的事件提取结果。跨五个领域和六种大语言模型的实验表明，该框架持续优于现有零样本基线，彰显了将事件提取视作代码生成的价值。代码与数据已发布于https://github.com/UESTC-GQJ/Agent-Event-Coder。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Zero-shot event extraction poses challenges for large language models due to complex reasoning requirements and domain-specific knowledge gaps, often resulting in incomplete or invalid outputs. To address this, the authors propose Agent-Event-Coder (AEC), a multi-agent framework that treats event extraction as a structured code-generation process, decomposing it into specialized subtasks handled by dedicated agents for retrieval, planning, coding, and verification. Experimental results across five domains and six LLMs show that AEC consistently outperforms prior zero-shot baselines, demonstrating improved precision, completeness, and schema consistency in event extraction.</div>
<div class="mono" style="margin-top:8px">零样本事件抽取因需要复杂推理和领域特定理解而对大语言模型构成挑战，直接提示常导致输出不完整或结构无效。为此，研究者提出Agent-Event-Coder（AEC）多智能体框架，将事件抽取视为结构化代码生成过程，通过检索、规划、编码和验证等专门智能体分解任务。在五个领域和六种大模型上的实验表明，AEC持续优于现有零样本基线，实现了更精确且符合模式的事件抽取。</div>
</details>
</div>
<div class="card">
<div class="title">MMEdge: Accelerating On-device Multimodal Inference via Pipelined Sensing and Encoding</div>
<div class="meta-line">Authors: Runxi Huang, Mingxuan Yu, Mingyu Tsoi, Xiaomin Ouyang</div>
<div class="meta-line">First: 2025-10-29T09:41:03+00:00 · Latest: 2025-11-17T08:01:11+00:00</div>
<div class="meta-line">Comments: Code available at: https://github.com/HKUST-MINSys-Lab/MMEdge. Accepted by SenSys 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.25327v4">Abs</a> · <a href="https://arxiv.org/pdf/2510.25327v4">PDF</a> · <a href="https://github.com/HKUST-MINSys-Lab/MMEdge">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Real-time multimodal inference on resource-constrained edge devices is essential for applications such as autonomous driving, human-computer interaction, and mobile health. However, prior work often overlooks the tight coupling between sensing dynamics and model execution, as well as the complex inter-modality dependencies. In this paper, we propose MMEdge, an new on-device multi-modal inference framework based on pipelined sensing and encoding. Instead of waiting for complete sensor inputs, MMEdge decomposes the entire inference process into a sequence of fine-grained sensing and encoding units, allowing computation to proceed incrementally as data arrive. MMEdge also introduces a lightweight but effective temporal aggregation module that captures rich temporal dynamics across different pipelined units to maintain accuracy performance. Such pipelined design also opens up opportunities for fine-grained cross-modal optimization and early decision-making during inference. To further enhance system performance under resource variability and input data complexity, MMEdge incorporates an adaptive multimodal configuration optimizer that dynamically selects optimal sensing and model configurations for each modality under latency constraints, and a cross-modal speculative skipping mechanism that bypasses future units of slower modalities when early predictions reach sufficient confidence. We evaluate MMEdge using two public multimodal datasets and deploy it on a real-world unmanned aerial vehicle (UAV)-based multimodal testbed. The results show that MMEdge significantly reduces end-to-end latency while maintaining high task accuracy across various system and data dynamics.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MMEdge：通过流水线感知与编码加速端侧多模态推理</div>
<div class="mono" style="margin-top:8px">资源受限边缘设备上的实时多模态推理对于自动驾驶、人机交互和移动健康等应用至关重要。然而现有研究常忽略感知动态与模型执行的紧密耦合关系以及复杂的模态间依赖。本文提出MMEdge——基于流水线感知与编码的新型端侧多模态推理框架。该框架无需等待完整传感器输入，而是将整个推理过程分解为细粒度感知编码单元序列，实现数据抵达时的增量式计算。MMEdge还引入轻量级时序聚合模块，通过捕捉跨流水线单元的丰富时序动态来维持精度性能。这种流水线设计同时为细粒度跨模态优化和推理过程中的早期决策创造了条件。为提升系统在资源波动和输入数据复杂性下的表现，MMEdge集成了自适应多模态配置优化器（在延迟约束下动态选择各模态最优感知与模型配置）和跨模态推测跳过机制（当早期预测达到足够置信度时跳过慢速模态的后续单元）。我们在两个公共多模态数据集上评估MMEdge，并将其部署于真实无人机多模态测试平台。结果表明，MMEdge在保持各类系统与数据动态下高任务精度的同时，显著降低了端到端延迟。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the challenge of real-time multimodal inference on resource-constrained edge devices, where prior approaches overlooked the coupling between sensing dynamics and model execution. The proposed MMEdge framework employs pipelined sensing and encoding to decompose inference into fine-grained units that process data incrementally, enhanced by a temporal aggregation module for accuracy and adaptive optimization mechanisms for dynamic resource management. Experimental evaluation on public datasets and a UAV testbed demonstrates that MMEdge significantly reduces end-to-end latency while maintaining high task accuracy under varying system conditions.</div>
<div class="mono" style="margin-top:8px">本研究针对资源受限边缘设备上的实时多模态推理挑战，以往方法常忽略感知动态与模型执行间的紧密耦合。提出的MMEdge框架采用流水线式感知与编码方法，将推理分解为细粒度单元，实现数据到达时的增量处理。它通过时序聚合模块保持准确性，并采用自适应配置优化和跨模态推测跳过来提升资源受限下的效率。在公共数据集和无人机测试平台上的实验表明，MMEdge在多种系统条件下显著降低了端到端延迟，同时保持了高任务精度。</div>
</details>
</div>
<div class="card">
<div class="title">Transformer-Based Scalable Multi-Agent Reinforcement Learning for Networked Systems with Long-Range Interactions</div>
<div class="meta-line">Authors: Vidur Sinha, Muhammed Ustaomeroglu, Guannan Qu</div>
<div class="meta-line">First: 2025-11-17T07:58:13+00:00 · Latest: 2025-11-17T07:58:13+00:00</div>
<div class="meta-line">Comments: 8 pages, 7 figures, submitted for review</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.13103v1">Abs</a> · <a href="https://arxiv.org/pdf/2511.13103v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multi-agent reinforcement learning (MARL) has shown promise for large-scale network control, yet existing methods face two major limitations. First, they typically rely on assumptions leading to decay properties of local agent interactions, limiting their ability to capture long-range dependencies such as cascading power failures or epidemic outbreaks. Second, most approaches lack generalizability across network topologies, requiring retraining when applied to new graphs. We introduce STACCA (Shared Transformer Actor-Critic with Counterfactual Advantage), a unified transformer-based MARL framework that addresses both challenges. STACCA employs a centralized Graph Transformer Critic to model long-range dependencies and provide system-level feedback, while its shared Graph Transformer Actor learns a generalizable policy capable of adapting across diverse network structures. Further, to improve credit assignment during training, STACCA integrates a novel counterfactual advantage estimator that is compatible with state-value critic estimates. We evaluate STACCA on epidemic containment and rumor-spreading network control tasks, demonstrating improved performance, network generalization, and scalability. These results highlight the potential of transformer-based MARL architectures to achieve scalable and generalizable control in large-scale networked systems.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于Transformer的具有长程交互作用的网络系统可扩展多智能体强化学习</div>
<div class="mono" style="margin-top:8px">多智能体强化学习（MARL）在大规模网络控制中展现出潜力，但现有方法存在两大局限：其一，通常依赖导致局部智能体交互衰减特性的假设，限制了捕捉级联停电或疫情传播等长程依赖的能力；其二，多数方法缺乏跨网络拓扑的泛化性，需在新图结构上重新训练。我们提出STACCA（共享Transformer行动者-批判者与反事实优势），这是一个基于Transformer的统一MARL框架，通过集中式图Transformer批判者建模长程依赖并提供系统级反馈，同时其共享图Transformer行动者学习能适应不同网络结构的可泛化策略。此外，为改进训练中的信用分配，STACCA集成了与状态值批判者估计兼容的新型反事实优势估计器。在疫情遏制和谣言传播网络控制任务上的实验表明，该方法具有更优性能、网络泛化能力和可扩展性，彰显了基于Transformer的MARL架构在大规模网络系统中实现可扩展与可泛化控制的潜力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Existing multi-agent reinforcement learning methods for network control struggle with capturing long-range dependencies and generalizing across network topologies, limiting their applicability to scenarios like cascading failures or epidemic outbreaks. To address this, the authors propose STACCA, a transformer-based MARL framework featuring a centralized Graph Transformer Critic for modeling long-range dependencies and a shared Graph Transformer Actor for learning topology-agnostic policies, enhanced by a counterfactual advantage estimator for improved credit assignment. Experimental results on epidemic containment and rumor-spreading tasks demonstrate that STACCA achieves superior performance, better network generalization, and enhanced scalability compared to existing approaches.</div>
<div class="mono" style="margin-top:8px">现有网络系统中的多智能体强化学习方法难以捕捉长程依赖关系，且缺乏跨网络拓扑的泛化能力。为此，研究者提出STACCA框架，采用集中式图变换器评论家建模长程交互，共享图变换器执行器学习可迁移策略，并结合反事实优势估计器优化信用分配。在疫情控制和谣言传播任务上的实验表明，该方法在性能、网络泛化能力和可扩展性方面均优于现有方法。</div>
</details>
</div>
<div class="card">
<div class="title">ResAlignNet: A Data-Driven Approach for INS/DVL Alignment</div>
<div class="meta-line">Authors: Guy Damari, Itzik Klein</div>
<div class="meta-line">First: 2025-11-17T07:50:44+00:00 · Latest: 2025-11-17T07:50:44+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.13096v1">Abs</a> · <a href="https://arxiv.org/pdf/2511.13096v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Autonomous underwater vehicles rely on precise navigation systems that combine the inertial navigation system and the Doppler velocity log for successful missions in challenging environments where satellite navigation is unavailable. The effectiveness of this integration critically depends on accurate alignment between the sensor reference frames. Standard model-based alignment methods between these sensor systems suffer from lengthy convergence times, dependence on prescribed motion patterns, and reliance on external aiding sensors, significantly limiting operational flexibility. To address these limitations, this paper presents ResAlignNet, a data-driven approach using the 1D ResNet-18 architecture that transforms the alignment problem into deep neural network optimization, operating as an in-situ solution that requires only sensors on board without external positioning aids or complex vehicle maneuvers, while achieving rapid convergence in seconds. Additionally, the approach demonstrates the learning capabilities of Sim2Real transfer, enabling training in synthetic data while deploying in operational sensor measurements. Experimental validation using the Snapir autonomous underwater vehicle demonstrates that ResAlignNet achieves alignment accuracy within 0.8° using only 25 seconds of data collection, representing a 65\% reduction in convergence time compared to standard velocity-based methods. The trajectory-independent solution eliminates motion pattern requirements and enables immediate vehicle deployment without lengthy pre-mission procedures, advancing underwater navigation capabilities through robust sensor-agnostic alignment that scales across different operational scenarios and sensor specifications.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>ResAlignNet：一种数据驱动的INS/DVL对准方法</div>
<div class="mono" style="margin-top:8px">自主水下航行器依赖惯性导航系统与多普勒计程仪组合的精密导航系统，在卫星导航不可用的复杂环境中执行任务。该融合效能关键取决于传感器参考系间的精确对准。传统基于模型的传感器对准方法存在收敛时间长、依赖预设运动轨迹和外部辅助传感器等问题，严重限制作业灵活性。为此，本文提出ResAlignNet——采用一维ResNet-18架构的数据驱动方案，将对准问题转化为深度神经网络优化，作为原位解决方案仅需船载传感器，无需外部定位辅助或复杂机动动作，即可在数秒内实现快速收敛。该方法还展示了Sim2Real迁移的学习能力，支持在合成数据中训练后直接部署于实际传感器测量。基于Snapir自主水下航行器的实验验证表明，ResAlignNet仅需25秒数据采集即可实现0.8°以内的对准精度，相比标准速度法收敛时间缩短65%。这种轨迹无关方案消除了运动模式要求，无需冗长任务前准备即可立即部署，通过适用于不同作业场景与传感器规格的鲁棒传感器无关对准技术，显著提升了水下导航能力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Autonomous underwater vehicles require precise alignment between inertial navigation systems and Doppler velocity logs for reliable navigation in GPS-denied environments, but conventional model-based methods suffer from slow convergence, dependency on specific motion patterns, and external aiding sensors. To overcome these limitations, ResAlignNet introduces a data-driven approach using a 1D ResNet-18 architecture that reformulates alignment as a deep neural network optimization problem, enabling in-situ operation without external aids or complex maneuvers and supporting Sim2Real transfer from synthetic to real sensor data. Experimental results with the Snapir AUV show that ResAlignNet achieves alignment accuracy within 0.8° using only 25 seconds of data, reducing convergence time by 65% compared to standard velocity-based methods while eliminating motion dependencies and enabling immediate deployment.</div>
<div class="mono" style="margin-top:8px">自主水下航行器在无卫星导航的复杂环境中依赖惯性导航系统与多普勒计程仪间的精确对准，但传统基于模型的方法存在收敛慢、依赖特定运动模式和外部辅助传感器的问题。为此，ResAlignNet提出一种数据驱动方法，采用一维ResNet-18架构将对准问题转化为深度神经网络优化，实现无需外部辅助或复杂机动的原位操作，并支持从合成数据到真实传感器的Sim2Real迁移。在Snapir自主水下航行器上的实验表明，该方法仅用25秒数据即可实现0.8°以内的对准精度，相比标准速度法收敛时间减少65%，且无需运动模式要求，可实现即时部署。</div>
</details>
</div>
<div class="card">
<div class="title">Look Before You Leap: A GUI-Critic-R1 Model for Pre-Operative Error Diagnosis in GUI Automation</div>
<div class="meta-line">Authors: Yuyang Wanyan, Xi Zhang, Haiyang Xu, Haowei Liu, Junyang Wang, Jiabo Ye, Yutong Kou, Ming Yan, Fei Huang, Xiaoshan Yang, Weiming Dong, Changsheng Xu</div>
<div class="meta-line">First: 2025-06-05T04:12:36+00:00 · Latest: 2025-11-17T07:48:59+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.04614v2">Abs</a> · <a href="https://arxiv.org/pdf/2506.04614v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In recent years, Multimodal Large Language Models (MLLMs) have been extensively utilized for multimodal reasoning tasks, including Graphical User Interface (GUI) automation. Unlike general offline multimodal tasks, GUI automation is executed in online interactive environments, necessitating step-by-step decision-making based on real-time status of the environment. This task has a lower tolerance for decision-making errors at each step, as any mistakes may cumulatively disrupt the process and potentially lead to irreversible outcomes like deletions or payments. To address these issues, we introduce a pre-operative critic mechanism that provides effective feedback prior to the actual execution, by reasoning about the potential outcome and correctness of actions. Specifically, we propose a Suggestion-aware Gradient Relative Policy Optimization (S-GRPO) strategy to construct our pre-operative critic model GUI-Critic-R1, incorporating a novel suggestion reward to enhance the reliability of the model&#x27;s feedback. Furthermore, we develop a reasoning-bootstrapping based data collection pipeline to create a GUI-Critic-Train and a GUI-Critic-Test, filling existing gaps in GUI critic data. Static experiments on the GUI-Critic-Test across both mobile and web domains reveal that our GUI-Critic-R1 offers significant advantages in critic accuracy compared to current MLLMs. Dynamic evaluation on GUI automation benchmark further highlights the effectiveness and superiority of our model, as evidenced by improved success rates and operational efficiency.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>三思而后行：用于GUI自动化术前错误诊断的GUI-Critic-R1模型</div>
<div class="mono" style="margin-top:8px">近年来，多模态大语言模型已被广泛应用于包括图形用户界面自动化在内的多模态推理任务。与通用离线多模态任务不同，GUI自动化在在线交互环境中执行，需要根据环境实时状态进行逐步决策。该任务对每一步决策错误的容忍度较低，因为任何失误都可能累积破坏流程，甚至导致删除或支付等不可逆后果。针对这些问题，我们引入术前评审机制，通过推理行动潜在结果与正确性，在实际执行前提供有效反馈。具体提出建议感知梯度相对策略优化方案构建术前评审模型GUI-Critic-R1，融入新型建议奖励以增强模型反馈可靠性。此外，开发基于推理引导的数据收集流程，构建GUI-Critic-Train与GUI-Critic-Test数据集，填补现有GUI评审数据空白。在移动端与网页端的GUI-Critic-Test静态实验表明，相较于当前多模态大语言模型，我们的GUI-Critic-R1在评审准确率上具有显著优势。GUI自动化基准的动态评估进一步验证了模型效能与优越性，具体体现在成功率和操作效率的全面提升。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the critical need for error prevention in GUI automation, where cumulative mistakes in online interactive environments can lead to irreversible consequences such as deletions or payments. The authors propose a pre-operative critic mechanism that evaluates potential action outcomes before execution, implemented through a Suggestion-aware Gradient Relative Policy Optimization (S-GRPO) strategy to build the GUI-Critic-R1 model with enhanced feedback reliability. Experimental results demonstrate that GUI-Critic-R1 achieves significantly higher critic accuracy than existing MLLMs in static tests across mobile and web domains, while dynamic evaluations on GUI automation benchmarks confirm improved success rates and operational efficiency.</div>
<div class="mono" style="margin-top:8px">本研究针对图形用户界面自动化中错误预防的迫切需求展开，在线交互环境中的累积错误可能导致删除或支付等不可逆后果。作者提出了一种术前评判机制，通过建议感知梯度相对策略优化方法构建GUI-Critic-R1模型，在动作执行前评估潜在结果并利用建议奖励提升反馈可靠性。实验结果表明，在移动端和网页端的静态测试中，该模型相比现有多模态大语言模型显著提高了评判准确率；在自动化基准的动态评估中，其成功率和操作效率也得到明显提升。</div>
</details>
</div>
<div class="card">
<div class="title">MEGA-GUI: Multi-stage Enhanced Grounding Agents for GUI Elements</div>
<div class="meta-line">Authors: SeokJoo Kwak, Jihoon Kim, Boyoun Kim, Jung Jae Yoon, Wooseok Jang, Jeonghoon Hong, Jaeho Yang, Yeong-Dae Kwon</div>
<div class="meta-line">First: 2025-11-17T07:38:05+00:00 · Latest: 2025-11-17T07:38:05+00:00</div>
<div class="meta-line">Comments: 26 pages, 7 figures. Code available at https://github.com/samsungsds-research-papers/mega-gui</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.13087v1">Abs</a> · <a href="https://arxiv.org/pdf/2511.13087v1">PDF</a> · <a href="https://github.com/samsungsds-research-papers/mega-gui">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Graphical User Interface (GUI) grounding - the task of mapping natural language instructions to screen coordinates - is essential for autonomous agents and accessibility technologies. Existing systems rely on monolithic models or one-shot pipelines that lack modularity and fail under visual clutter and ambiguous instructions. We introduce MEGA-GUI, a multi-stage framework that separates grounding into coarse Region-of-Interest (ROI) selection and fine-grained element grounding, orchestrated by specialized vision-language agents. MEGA-GUI features a bidirectional ROI zoom algorithm that mitigates spatial dilution and a context-aware rewriting agent that reduces semantic ambiguity. Our analysis reveals complementary strengths and weaknesses across vision-language models at different visual scales, and we show that leveraging this modular structure achieves consistently higher accuracy than monolithic approaches. On the visually dense ScreenSpot-Pro benchmark, MEGA-GUI attains 73.18% accuracy, and on the semantically complex OSWorld-G benchmark it reaches 68.63%, surpassing previously reported results. Code and the Grounding Benchmark Toolkit (GBT) are available at https://github.com/samsungsds-research-papers/mega-gui.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MEGA-GUI：面向图形用户界面元素的多阶段增强式定位智能体</div>
<div class="mono" style="margin-top:8px">图形用户界面定位——将自然语言指令映射到屏幕坐标的任务——对自主智能体和无障碍技术至关重要。现有系统依赖单体模型或缺乏模块化的单步流程，在视觉杂乱和模糊指令下容易失效。我们提出MEGA-GUI多阶段框架，通过专业视觉语言智能体将定位分解为粗粒度兴趣区域选择和细粒度元素定位。该框架采用双向ROI缩放算法缓解空间稀释问题，配备语境感知重写智能体降低语义歧义。分析表明不同视觉尺度的视觉语言模型存在互补性优势，利用这种模块化结构能持续获得优于单体方法的准确率。在视觉密集的ScreenSpot-Pro基准测试中达到73.18%准确率，在语义复杂的OSWorld-G基准测试中取得68.63%准确率，超越已有记录。代码及定位基准工具包见：https://github.com/samsungsds-research-papers/mega-gui</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Graphical User Interface grounding requires mapping natural language instructions to screen coordinates, but existing monolithic models struggle with visual clutter and ambiguous instructions. MEGA-GUI addresses this by introducing a multi-stage framework that separates grounding into coarse Region-of-Interest selection and fine-grained element grounding, utilizing specialized vision-language agents with a bidirectional ROI zoom algorithm and context-aware rewriting to reduce spatial dilution and semantic ambiguity. Experimental results demonstrate that this modular approach consistently outperforms monolithic models, achieving 73.18% accuracy on the visually dense ScreenSpot-Pro benchmark and 68.63% on the semantically complex OSWorld-G benchmark.</div>
<div class="mono" style="margin-top:8px">图形用户界面定位任务面临视觉杂乱和指令模糊的挑战，现有单体模型难以应对。MEGA-GUI提出多阶段框架，通过专用视觉语言代理将定位分解为粗粒度兴趣区域选择和细粒度元素定位，结合双向ROI缩放算法和上下文感知重写解决空间与语义问题。实验表明该方法在ScreenSpot-Pro基准上达到73.18%准确率，在OSWorld-G基准上达68.63%，通过模块化设计和模型优势互补显著超越现有方法。</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20251118_1028.html">20251118_1028</a>
<a href="archive/20251118_0328.html">20251118_0328</a>
<a href="archive/20251117_0326.html">20251117_0326</a>
<a href="archive/20251116_0325.html">20251116_0325</a>
<a href="archive/20251115_0327.html">20251115_0327</a>
<a href="archive/20251114_0328.html">20251114_0328</a>
<a href="archive/20251113_0330.html">20251113_0330</a>
<a href="archive/20251112_0329.html">20251112_0329</a>
<a href="archive/20251111_0328.html">20251111_0328</a>
<a href="archive/20251110_0325.html">20251110_0325</a>
<a href="archive/20251109_0326.html">20251109_0326</a>
<a href="archive/20251108_0328.html">20251108_0328</a>
<a href="archive/20251107_0328.html">20251107_0328</a>
<a href="archive/20251106_0329.html">20251106_0329</a>
<a href="archive/20251105_0326.html">20251105_0326</a>
<a href="archive/20251104_0327.html">20251104_0327</a>
<a href="archive/20251103_0324.html">20251103_0324</a>
<a href="archive/20251102_0326.html">20251102_0326</a>
<a href="archive/20251101_0324.html">20251101_0324</a>
<a href="archive/20251031_0328.html">20251031_0328</a>
<a href="archive/20251030_0330.html">20251030_0330</a>
<a href="archive/20251029_0329.html">20251029_0329</a>
<a href="archive/20251028_0329.html">20251028_0329</a>
<a href="archive/20251027_0322.html">20251027_0322</a>
<a href="archive/20251026_0327.html">20251026_0327</a>
<a href="archive/20251025_0331.html">20251025_0331</a>
<a href="archive/20251024_0329.html">20251024_0329</a>
<a href="archive/20251023_0329.html">20251023_0329</a>
<a href="archive/20251022_0330.html">20251022_0330</a>
<a href="archive/20251021_0331.html">20251021_0331</a>
<a href="archive/20251020_0328.html">20251020_0328</a>
<a href="archive/20251019_0321.html">20251019_0321</a>
<a href="archive/20251018_0327.html">20251018_0327</a>
<a href="archive/20251017_0320.html">20251017_0320</a>
<a href="archive/20251016_0328.html">20251016_0328</a>
<a href="archive/20251015_0328.html">20251015_0328</a>
<a href="archive/20251014_0323.html">20251014_0323</a>
<a href="archive/20251011_0328.html">20251011_0328</a>
<a href="archive/20251010_0330.html">20251010_0330</a>
<a href="archive/20251009_0321.html">20251009_0321</a>
<a href="archive/20251008_0343.html">20251008_0343</a>
<a href="archive/20251007_0353.html">20251007_0353</a>
<a href="archive/20251006_0325.html">20251006_0325</a>
<a href="archive/20251005_0350.html">20251005_0350</a>
<a href="archive/20251004_0352.html">20251004_0352</a>
<a href="archive/20251003_0352.html">20251003_0352</a>
<a href="archive/20251002_0356.html">20251002_0356</a>
<a href="archive/20251001_0321.html">20251001_0321</a>
<a href="archive/20250925_0335.html">20250925_0335</a>
<a href="archive/20250924_0350.html">20250924_0350</a>
<a href="archive/20250923_0348.html">20250923_0348</a>
<a href="archive/20250922_0346.html">20250922_0346</a>
<a href="archive/20250921_0345.html">20250921_0345</a>
<a href="archive/20250920_0342.html">20250920_0342</a>
<a href="archive/20250919_0346.html">20250919_0346</a>
<a href="archive/20250918_0342.html">20250918_0342</a>
<a href="archive/20250917_0336.html">20250917_0336</a>
<a href="archive/20250916_0333.html">20250916_0333</a>
<a href="archive/20250915_0333.html">20250915_0333</a>
<a href="archive/20250914_0328.html">20250914_0328</a>
<a href="archive/20250913_0322.html">20250913_0322</a>
<a href="archive/20250912_0335.html">20250912_0335</a>
<a href="archive/20250911_0337.html">20250911_0337</a>
<a href="archive/20250910_0338.html">20250910_0338</a>
<a href="archive/20250909_0341.html">20250909_0341</a>
<a href="archive/20250908_0342.html">20250908_0342</a>
<a href="archive/20250907_0333.html">20250907_0333</a>
<a href="archive/20250906_0350.html">20250906_0350</a>
<a href="archive/20250905_0319.html">20250905_0319</a>
<a href="archive/20250904_0323.html">20250904_0323</a>
<a href="archive/20250903_0355.html">20250903_0355</a>
<a href="archive/20250902_0325.html">20250902_0325</a>
<a href="archive/20250901_0355.html">20250901_0355</a>
<a href="archive/20250831_0355.html">20250831_0355</a>
<a href="archive/20250830_0356.html">20250830_0356</a>
<a href="archive/20250829_0355.html">20250829_0355</a>
<a href="archive/20250828_0333.html">20250828_0333</a>
<a href="archive/20250827_1654.html">20250827_1654</a>
<a href="archive/20250827_1602.html">20250827_1602</a>
<a href="archive/20250827_1557.html">20250827_1557</a>
<a href="archive/20250827_0320.html">20250827_0320</a>
<a href="archive/20250826_0320.html">20250826_0320</a>
<a href="archive/20250825_1752.html">20250825_1752</a>
<a href="archive/20250825_1709.html">20250825_1709</a>
<a href="archive/20250825_1652.html">20250825_1652</a>
<a href="archive/20250825_1647.html">20250825_1647</a>
<a href="archive/20250825_1645.html">20250825_1645</a>
<a href="archive/20250825_1631.html">20250825_1631</a>
<a href="archive/20250825_1606.html">20250825_1606</a>
<a href="archive/20250825_1559.html">20250825_1559</a>
<a href="archive/20250825_1558.html">20250825_1558</a>
<a href="archive/20250825_1556.html">20250825_1556</a>
<a href="archive/20250825_1531.html">20250825_1531</a>
<a href="archive/20250825_1525.html">20250825_1525</a>
<a href="archive/20250825_1516.html">20250825_1516</a>
<a href="archive/20250825_1450.html">20250825_1450</a>
<a href="archive/20250825_1444.html">20250825_1444</a>
<a href="archive/20250825_1438.html">20250825_1438</a>
<a href="archive/20250825_1414.html">20250825_1414</a>
<a href="archive/20250825_1413.html">20250825_1413</a>
<a href="archive/20250825_1410.html">20250825_1410</a>
<a href="archive/20250825_1408.html">20250825_1408</a>
<a href="archive/20250825_1405.html">20250825_1405</a>
<a href="archive/20250825_1401.html">20250825_1401</a>
<a href="archive/20250825_1355.html">20250825_1355</a>
<a href="archive/20250825_1347.html">20250825_1347</a>
<a href="archive/20250825_1345.html">20250825_1345</a>
<a href="archive/20250825_1344.html">20250825_1344</a>
<a href="archive/20250825_1343.html">20250825_1343</a>
<a href="archive/20250825_1340.html">20250825_1340</a>
<a href="archive/20250825_1339.html">20250825_1339</a>
<a href="archive/20250825_1333.html">20250825_1333</a>
<a href="archive/20250825_1323.html">20250825_1323</a>
<a href="archive/20250825_1317.html">20250825_1317</a>
<a href="archive/20250825_1243.html">20250825_1243</a>
<a href="archive/20250824_0342.html">20250824_0342</a>
<a href="archive/20250823_0343.html">20250823_0343</a>
<a href="archive/20250823_0142.html">20250823_0142</a>
<a href="archive/20250822_2331.html">20250822_2331</a>
<a href="archive/20250822_2308.html">20250822_2308</a>
<a href="archive/20250822_2258.html">20250822_2258</a>
<a href="archive/20250822_2241.html">20250822_2241</a>
<a href="archive/20250822_2228.html">20250822_2228</a>
<a href="archive/20250822_2206.html">20250822_2206</a>
<a href="archive/20250822_2147.html">20250822_2147</a>
<a href="archive/20250822_2111.html">20250822_2111</a>
<a href="archive/20250822_1259.html">20250822_1259</a>
<a href="archive/20250822_1233.html">20250822_1233</a>
<a href="archive/20250822_1229.html">20250822_1229</a>
<a href="archive/20250822_1223.html">20250822_1223</a>
<a href="archive/20250822_1210.html">20250822_1210</a>
<a href="archive/20250822_1201.html">20250822_1201</a>
<a href="archive/20250822_1111.html">20250822_1111</a>
<a href="archive/20250822_1058.html">20250822_1058</a>
<a href="archive/20250822_1052.html">20250822_1052</a>
<a href="archive/20250822_1045.html">20250822_1045</a>
<a href="archive/20250822_0657.html">20250822_0657</a>
<a href="archive/20250822_0553.html">20250822_0553</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
